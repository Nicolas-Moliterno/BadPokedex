{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Federated Learning com Flower + DLG Attack\n",
        "\n",
        "Este notebook implementa:\n",
        "1. Federated Learning usando Flower\n",
        "2. Ataque DLG (Deep Leakage from Gradients) para demonstrar vulnerabilidades de privacidade"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Instalação de Dependências"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-25 16:41:02.061120: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-11-25 16:41:02.061721: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-11-25 16:41:02.063533: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-11-25 16:41:02.069454: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-11-25 16:41:02.080963: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-11-25 16:41:02.080994: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-11-25 16:41:02.088527: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-11-25 16:41:02.559190: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Usando o dispositivo: cuda\n",
            "Imports OK — utils carregado corretamente.\n",
            "✓ Imports completos\n"
          ]
        }
      ],
      "source": [
        "# --- Colar esta célula como a PRIMEIRA no notebook ---\n",
        "\n",
        "import os\n",
        "# Opcional: se você NÃO pretende usar TensorFlow aqui, NÃO importe tf (melhor evitar conflito com PyTorch)\n",
        "# Se por algum motivo precisar importar TF, descomente as 2 linhas abaixo para suprimir logs e evitar prints.\n",
        "# os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"  # suprime INFO/WARNING do TF (0=all, 3=ERROR only)\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"  # se quiser FORÇAR TF a não ver GPUs (cuidado: também afeta PyTorch)\n",
        "\n",
        "import sys\n",
        "# garante que módulos locais sob /mnt/data (utils.py, flwr_datasets, etc.) sejam encontrados\n",
        "sys.path.append(\".\")\n",
        "# também opcional: adicionar o diretório do notebook (caso esteja rodando a partir de outro cwd)\n",
        "sys.path.append(os.getcwd())\n",
        "\n",
        "# Agora faça os imports de bibliotecas e módulos (após sys.path.append)\n",
        "import flwr as fl\n",
        "import numpy as np\n",
        "\n",
        "# IMPORTS DO FLWR DATASETS (se é um módulo local, agora será encontrado)\n",
        "from flwr_datasets import FederatedDataset\n",
        "from flwr_datasets.partitioner import IidPartitioner, DirichletPartitioner\n",
        "\n",
        "# Imports do Flower para servidor\n",
        "from flwr.common import parameters_to_ndarrays, ndarrays_to_parameters\n",
        "from flwr.common import FitIns, EvaluateIns\n",
        "from flwr.server.strategy.aggregate import aggregate\n",
        "\n",
        "# Torch (deixe por último, depois de tratar env vars se necessário)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# IMPORTS LOCAIS\n",
        "import utils  # importar o módulo inteiro (import utils é necessário para referências utils.foo em atores remotos)\n",
        "\n",
        "# Opcional: atalhos (mantém nomes no namespace)\n",
        "from utils import (\n",
        "    cria_dataset,\n",
        "    weights_init,\n",
        "    label_to_onehot,\n",
        "    get_imagem_e_label,\n",
        "    cria_ruido,\n",
        "    mostra_imagem,\n",
        "    cross_entropy_for_onehot,\n",
        "    compara_imagens\n",
        ")\n",
        "\n",
        "print(\"Imports OK — utils carregado corretamente.\")\n",
        "print(\"✓ Imports completos\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Código Cliente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ----------------------------\n",
        "# Bloco 2 — Classe do Cliente \n",
        "# ----------------------------\n",
        "\n",
        "import torch\n",
        "\n",
        "class GradientQuantizer:\n",
        "    def __init__(self, num_bits=8):\n",
        "        self.num_bits = num_bits\n",
        "        self.num_levels = 2 ** num_bits\n",
        "\n",
        "    def quantize_gradients(self, gradients):\n",
        "        \"\"\"Quantização com escala GLOBAL.\"\"\"\n",
        "        quantized_grads = []\n",
        "\n",
        "        # Flatten de todos para achar min/max global\n",
        "        all_values = torch.cat([\n",
        "            g.flatten() for g in gradients \n",
        "            if g is not None\n",
        "        ])\n",
        "\n",
        "        global_min = all_values.min().item()\n",
        "        global_max = all_values.max().item()\n",
        "\n",
        "        scale = (global_max - global_min) / (self.num_levels - 1)\n",
        "        if scale == 0:\n",
        "            scale = 1.0\n",
        "\n",
        "        for g in gradients:\n",
        "            if g is None:\n",
        "                quantized_grads.append(None)\n",
        "                continue\n",
        "\n",
        "            q = torch.round((g - global_min) / scale)\n",
        "            q = torch.clamp(q, 0, self.num_levels - 1)\n",
        "\n",
        "            dtype = torch.uint8 if self.num_bits <= 8 else torch.int16\n",
        "            quantized_grads.append(q.to(dtype))\n",
        "\n",
        "        metadata = {\n",
        "            \"min\": global_min,\n",
        "            \"max\": global_max,\n",
        "            \"num_bits\": self.num_bits,\n",
        "        }\n",
        "\n",
        "        return quantized_grads, metadata\n",
        "\n",
        "    def dequantize_gradients(self, quantized_grads, metadata):\n",
        "        \"\"\"Reconstrói gradientes usando min/max global.\"\"\"\n",
        "        dequantized = []\n",
        "\n",
        "        global_min = metadata[\"min\"]\n",
        "        global_max = metadata[\"max\"]\n",
        "        scale = (global_max - global_min) / (self.num_levels - 1)\n",
        "\n",
        "        for q in quantized_grads:\n",
        "            if q is None:\n",
        "                dequantized.append(None)\n",
        "                continue\n",
        "\n",
        "            dq = q.float() * scale + global_min\n",
        "            dequantized.append(dq)\n",
        "\n",
        "        return dequantized\n",
        "\n",
        "    def aggregate_quantized(self, quantized_grads_list, weights_list):\n",
        "        \"\"\"Agregação dos gradientes quantizados.\"\"\"\n",
        "        if not quantized_grads_list:\n",
        "            return []\n",
        "\n",
        "        total_weight = sum(weights_list)\n",
        "        num_params = len(quantized_grads_list[0])\n",
        "        aggregated = []\n",
        "\n",
        "        for idx in range(num_params):\n",
        "            weighted_sum = None\n",
        "\n",
        "            for client_grads, weight in zip(quantized_grads_list, weights_list):\n",
        "                if idx >= len(client_grads):\n",
        "                    continue\n",
        "\n",
        "                g = client_grads[idx]\n",
        "                if g is None:\n",
        "                    continue\n",
        "\n",
        "                g_float = g.float() * (weight / total_weight)\n",
        "\n",
        "                if weighted_sum is None:\n",
        "                    weighted_sum = g_float\n",
        "                else:\n",
        "                    weighted_sum += g_float\n",
        "\n",
        "            if weighted_sum is not None:\n",
        "                q = torch.round(weighted_sum)\n",
        "                dtype = torch.uint8 if self.num_bits <= 8 else torch.int16\n",
        "                aggregated.append(q.clamp(0, self.num_levels - 1).to(dtype))\n",
        "            else:\n",
        "                aggregated.append(None)\n",
        "\n",
        "        return aggregated\n",
        "\n",
        "    def compress_ratio(self):\n",
        "        \"\"\"Retorna taxa de compressão teórica.\"\"\"\n",
        "        return 32 / self.num_bits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Bloco corrigido: ClienteComQuantizacao\n",
        "import numpy as np\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import gc\n",
        "\n",
        "import utils  # garante o uso do utils.cria_dataset/cria_modelo\n",
        "\n",
        "class ClienteComQuantizacao(fl.client.NumPyClient):\n",
        "    def __init__(\n",
        "        self,\n",
        "        cid,\n",
        "        niid,\n",
        "        num_clients,\n",
        "        dirichlet_alpha,\n",
        "        quantizer=None,\n",
        "        dataset_path=\"/home/nicolas/Documentos/topicos_sistemas_distribuidos/trabalho/DATASETS/Pokedex_v14\"\n",
        "    ):\n",
        "        self.cid = int(cid)\n",
        "        self.niid = niid\n",
        "        self.num_clients = num_clients\n",
        "        self.dirichlet_alpha = dirichlet_alpha\n",
        "        self.quantizer = quantizer\n",
        "        self.dataset_path = dataset_path\n",
        "\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        print(f\"[Cliente {self.cid}] Device: {self.device}\")\n",
        "\n",
        "        # Carregar dataset completo com o transform correto (do utils)\n",
        "        # utils.cria_dataset retorna (dataset, transform)\n",
        "        full_dataset, self.transform = utils.cria_dataset(\"pokemon\", dataset_path=self.dataset_path)\n",
        "\n",
        "        # Particionar localmente para este cliente\n",
        "        self.full_dataset = full_dataset  # guardamos para create_model e debugging\n",
        "        self.train_dataset, self.test_dataset = self.load_data()\n",
        "\n",
        "        # Criar modelo usando o dataset (garante num_classes correto)\n",
        "        self.model = self.create_model()\n",
        "        self.model.to(self.device)\n",
        "\n",
        "        try:\n",
        "            self.num_train_samples = len(self.train_dataset)\n",
        "            self.num_test_samples = len(self.test_dataset)\n",
        "        except Exception:\n",
        "            self.num_train_samples = 0\n",
        "            self.num_test_samples = 0\n",
        "\n",
        "    # -------------------------\n",
        "    # utilitarios de parametros\n",
        "    # -------------------------\n",
        "    def get_parameters(self, config):\n",
        "        # Retorna lista de ndarrays (mesma ordem keys() do state_dict)\n",
        "        return [val.cpu().numpy() for val in self.model.state_dict().values()]\n",
        "\n",
        "    def set_parameters(self, parameters, config):\n",
        "        # Recebe lista de ndarrays; monta state_dict preservando a ordem das chaves\n",
        "        keys = list(self.model.state_dict().keys())\n",
        "        if len(keys) != len(parameters):\n",
        "            raise ValueError(f\"[Cliente {self.cid}] Número de parâmetros recebidos ({len(parameters)}) != esperado ({len(keys)})\")\n",
        "        state_dict = {k: torch.tensor(v, dtype=torch.float32) for k, v in zip(keys, parameters)}\n",
        "        self.model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "    # -------------------------\n",
        "    # dados locais (sem GLOBAL_DATASET)\n",
        "    # -------------------------\n",
        "    def load_data(self):\n",
        "        \"\"\"\n",
        "        Cria partição local do full_dataset (carregado via utils.cria_dataset).\n",
        "        Retorna (train_subset, test_subset) como torch Subset/SubsetRandomSplit.\n",
        "        \"\"\"\n",
        "        # full_dataset já salvo em self.full_dataset no __init__\n",
        "        num_samples = len(self.full_dataset)\n",
        "        indices = np.arange(num_samples)\n",
        "        np.random.seed(42)\n",
        "        np.random.shuffle(indices)\n",
        "\n",
        "        if self.niid:\n",
        "            # Distribuição NIID — usa 'dirichlet' style: simplificado com split igual aqui\n",
        "            # Se quiser a partição Dirichlet real, trocamos aqui.\n",
        "            split = np.array_split(indices, self.num_clients)\n",
        "            client_indices = split[self.cid]\n",
        "        else:\n",
        "            # IID: fatia intercalada\n",
        "            client_indices = indices[self.cid::self.num_clients]\n",
        "\n",
        "        # Criar subset para o cliente\n",
        "        client_subset = Subset(self.full_dataset, client_indices)\n",
        "\n",
        "        # Dividir em train/test 80/20 (local)\n",
        "        train_size = int(len(client_subset) * 0.8)\n",
        "        test_size = len(client_subset) - train_size\n",
        "        if train_size == 0:\n",
        "            # fallback mínimo\n",
        "            return client_subset, client_subset\n",
        "\n",
        "        train_subset, test_subset = torch.utils.data.random_split(\n",
        "            client_subset, [train_size, test_size], generator=torch.Generator().manual_seed(42)\n",
        "        )\n",
        "\n",
        "        return train_subset, test_subset\n",
        "\n",
        "    # -------------------------\n",
        "    # criar modelo com utils (garante compatibilidade)\n",
        "    # -------------------------\n",
        "    def create_model(self):\n",
        "        # Usa o full_dataset (ImageFolder com transform) para descobrir num_classes\n",
        "        return utils.cria_modelo(\"pokemon\", dataset=self.full_dataset)\n",
        "\n",
        "    # -------------------------\n",
        "    # fit: tuneado conforme tua lógica\n",
        "    # -------------------------\n",
        "    def fit(self, parameters, config):\n",
        "        try:\n",
        "            server_round = config.get('server_round', 0)\n",
        "            print(f\"\\n[Cliente {self.cid}] FIT RODADA {server_round}\")\n",
        "\n",
        "            # 1) sincronizar pesos\n",
        "            self.set_parameters(parameters, config)\n",
        "\n",
        "            # salvar pesos iniciais\n",
        "            initial_weights = [p.data.clone().cpu() for p in self.model.parameters()]\n",
        "\n",
        "            self.model.train()\n",
        "\n",
        "            IS_ATTACK_ROUND = (server_round == 1)\n",
        "\n",
        "            if IS_ATTACK_ROUND:\n",
        "                local_epochs = 1\n",
        "                batch_size = 1\n",
        "                lr = 0.01\n",
        "                optim_type = 'sgd'\n",
        "                label_smoothing = 0.0\n",
        "                use_clipping = False\n",
        "                shuffle_data = False\n",
        "            else:\n",
        "                local_epochs = 15\n",
        "                batch_size = 64\n",
        "                lr = 0.002\n",
        "                optim_type = 'adam'\n",
        "                label_smoothing = 0.1\n",
        "                use_clipping = True\n",
        "                shuffle_data = True\n",
        "\n",
        "            train_loader = DataLoader(\n",
        "                self.train_dataset,\n",
        "                batch_size=batch_size,\n",
        "                shuffle=shuffle_data,\n",
        "                num_workers=2,\n",
        "                pin_memory=True if self.device.type == 'cuda' else False\n",
        "            )\n",
        "\n",
        "            if optim_type == 'adam':\n",
        "                optimizer = optim.Adam(self.model.parameters(), lr=lr, weight_decay=1e-4)\n",
        "            else:\n",
        "                optimizer = optim.SGD(self.model.parameters(), lr=lr)\n",
        "\n",
        "            scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.8)\n",
        "            criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
        "\n",
        "            first_image_gradient = None\n",
        "            first_image_captured = False\n",
        "\n",
        "            total_samples = 0\n",
        "            total_correct = 0\n",
        "            running_loss = 0.0\n",
        "            stop_training = False\n",
        "\n",
        "            for epoch in range(local_epochs):\n",
        "                if stop_training:\n",
        "                    break\n",
        "\n",
        "                epoch_samples = 0\n",
        "                epoch_correct = 0\n",
        "                epoch_loss = 0.0\n",
        "\n",
        "                for i, (images, labels) in enumerate(train_loader):\n",
        "                    images, labels = images.to(self.device), labels.to(self.device)\n",
        "\n",
        "                    if not first_image_captured:\n",
        "                        self.model.zero_grad()\n",
        "                        single_output = self.model(images[0:1])\n",
        "                        single_loss = criterion(single_output, labels[0:1])\n",
        "                        single_loss.backward()\n",
        "\n",
        "                        # guarde gradientes (lista de tensores CPU)\n",
        "                        first_image_gradient = [\n",
        "                            (p.grad.detach().clone().cpu() if p.grad is not None else torch.zeros_like(p.data).cpu())\n",
        "                            for p in self.model.parameters()\n",
        "                        ]\n",
        "                        first_image_captured = True\n",
        "                        print(f\"[Cliente {self.cid}] Gradientes capturados! Label: {labels[0].item()}\")\n",
        "\n",
        "                    # treinamento normal\n",
        "                    optimizer.zero_grad()\n",
        "                    outputs = self.model(images)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    loss.backward()\n",
        "\n",
        "                    if use_clipping:\n",
        "                        torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
        "\n",
        "                    optimizer.step()\n",
        "\n",
        "                    _, predicted = outputs.max(1)\n",
        "                    batch_correct = predicted.eq(labels).sum().item()\n",
        "                    batch_samples = labels.size(0)\n",
        "\n",
        "                    epoch_samples += batch_samples\n",
        "                    epoch_correct += batch_correct\n",
        "                    epoch_loss += loss.item() * batch_samples\n",
        "\n",
        "                    if IS_ATTACK_ROUND:\n",
        "                        # interrompe após 1 batch (FedSGD)\n",
        "                        stop_training = True\n",
        "                        break\n",
        "\n",
        "                if not stop_training:\n",
        "                    scheduler.step()\n",
        "\n",
        "                total_samples += epoch_samples\n",
        "                total_correct += epoch_correct\n",
        "                running_loss += epoch_loss\n",
        "\n",
        "            avg_loss = running_loss / total_samples if total_samples > 0 else 0.0\n",
        "            avg_acc = total_correct / total_samples if total_samples > 0 else 0.0\n",
        "\n",
        "            current_weights = [p.data.cpu() for p in self.model.parameters()]\n",
        "\n",
        "            if first_image_gradient is None:\n",
        "                first_image_gradient = [torch.zeros_like(p).cpu() for p in self.model.parameters()]\n",
        "\n",
        "            print(f\"[Cliente {self.cid}] Fim Fit - Loss: {avg_loss:.4f}, Acc: {avg_acc:.4f}\")\n",
        "\n",
        "            # Preparar retorno (quantizado ou não)\n",
        "            if self.quantizer is not None:\n",
        "                quantized_weights, weight_metadata = self.quantizer.quantize_gradients(current_weights)\n",
        "                quantized_initial, initial_metadata = self.quantizer.quantize_gradients(initial_weights)\n",
        "                quantized_grads, grad_metadata = self.quantizer.quantize_gradients(first_image_gradient)\n",
        "\n",
        "                params_to_send = [w.cpu().numpy() if w is not None else None for w in quantized_weights]\n",
        "                initial_to_send = [w.cpu().numpy() if w is not None else None for w in quantized_initial]\n",
        "                grads_to_send = [g.cpu().numpy() if g is not None else None for g in quantized_grads]\n",
        "\n",
        "                fit_msg = {\n",
        "                    'cid': self.cid, 'accuracy': float(avg_acc), 'loss': float(avg_loss),\n",
        "                    'quantized': True,\n",
        "                    'quant_min': float(weight_metadata['min']), 'quant_max': float(weight_metadata['max']),\n",
        "                    'quant_bits': int(weight_metadata['num_bits']),\n",
        "                    'initial_quant_min': float(initial_metadata['min']), 'initial_quant_max': float(initial_metadata['max']),\n",
        "                    'grad_quant_min': float(grad_metadata['min']), 'grad_quant_max': float(grad_metadata['max']),\n",
        "                    'num_weights': len(params_to_send), 'num_initial': len(initial_to_send),\n",
        "                }\n",
        "            else:\n",
        "                params_to_send = [w.numpy() if w is not None else None for w in current_weights]\n",
        "                initial_to_send = [w.numpy() if w is not None else None for w in initial_weights]\n",
        "                grads_to_send = [g.numpy() if g is not None else None for g in first_image_gradient]\n",
        "\n",
        "                fit_msg = {\n",
        "                    'cid': self.cid, 'accuracy': float(avg_acc), 'loss': float(avg_loss),\n",
        "                    'quantized': False,\n",
        "                    'num_weights': len(params_to_send), 'num_initial': len(initial_to_send),\n",
        "                }\n",
        "\n",
        "            combined_params = params_to_send + initial_to_send + grads_to_send\n",
        "\n",
        "            self.log_client('train.csv', server_round, avg_acc, avg_loss)\n",
        "            print(f\"[Cliente {self.cid}] Retornando {len(combined_params)} parâmetros\")\n",
        "\n",
        "            # cleanup\n",
        "            del train_loader, optimizer, loss\n",
        "            torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "\n",
        "            return combined_params, int(self.num_train_samples), fit_msg\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ CRASH CLIENTE {self.cid}: {type(e).__name__}: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            raise\n",
        "\n",
        "    # -------------------------\n",
        "    # evaluate (único)\n",
        "    # -------------------------\n",
        "    def evaluate(self, parameters, config):\n",
        "        self.set_parameters(parameters, config)\n",
        "        self.model.eval()\n",
        "\n",
        "        test_loader = DataLoader(\n",
        "            self.test_dataset,\n",
        "            batch_size=128,\n",
        "            shuffle=False,\n",
        "            num_workers=0,\n",
        "            pin_memory=False\n",
        "        )\n",
        "\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        test_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_loader:\n",
        "                images, labels = images.to(self.device), labels.to(self.device)\n",
        "                outputs = self.model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                test_loss += loss.item()\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += labels.size(0)\n",
        "                correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        avg_loss = test_loss / len(test_loader) if len(test_loader) > 0 else 0.0\n",
        "        accuracy = correct / total if total > 0 else 0.0\n",
        "\n",
        "        eval_msg = {\n",
        "            'cid': self.cid,\n",
        "            'accuracy': accuracy,\n",
        "            'loss': avg_loss\n",
        "        }\n",
        "\n",
        "        self.log_client('evaluate.csv', config.get('server_round', -1), accuracy, avg_loss)\n",
        "        return avg_loss, int(self.num_test_samples), eval_msg\n",
        "\n",
        "    # -------------------------\n",
        "    # logging simples\n",
        "    # -------------------------\n",
        "    def log_client(self, file_name, server_round, acc, loss):\n",
        "        try:\n",
        "            with open(file_name, 'a') as file:\n",
        "                file.write(f'{server_round}, {self.cid}, {acc}, {loss}\\n')\n",
        "        except Exception:\n",
        "            pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Código Servidor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===== Globals para captura e acesso fora do worker (Notebook)\n",
        "GLOBAL_GRADS = {}        # chave: (rodada, cid) -> lista de gradientes (numpy/torch)\n",
        "GLOBAL_WEIGHTS = {}      # chave: (rodada, cid) -> pesos finais\n",
        "GLOBAL_INITIALS = {}     # chave: (rodada, cid) -> pesos iniciais\n",
        "GLOBAL_METADATA = {}     # chave: (rodada, cid) -> metadata (min/max/num_bits)\n",
        "\n",
        "# OPTIONAL: local disk dump for persistence (descomente se quiser)\n",
        "# import pickle, os\n",
        "# PERSIST_DIR = \"/tmp/fl_captures\"\n",
        "# os.makedirs(PERSIST_DIR, exist_ok=True)\n",
        "\n",
        "class ServidorComQuantizacao(fl.server.strategy.FedAvg):\n",
        "    def __init__(self, num_clients, dirichlet_alpha, fraction_fit=0.5, quantizer=None):\n",
        "        super().__init__(\n",
        "            fraction_fit=fraction_fit,\n",
        "            min_available_clients=num_clients\n",
        "        )\n",
        "\n",
        "        self.num_clients = num_clients\n",
        "        self.dirichlet_alpha = dirichlet_alpha\n",
        "        self.quantizer = quantizer\n",
        "\n",
        "        # Mantemos como opcional/local (não usados para comunicação com notebook)\n",
        "        self.intercepted_gradients = {}\n",
        "        self.intercepted_weights = {}\n",
        "        self.intercepted_initials = {}\n",
        "\n",
        "        self.metadata_grad = {}\n",
        "        self.metadata_weights = {}\n",
        "        self.metadata_initial = {}\n",
        "\n",
        "        self.global_quantized_weights = None\n",
        "        self.global_metadata = None\n",
        "\n",
        "    def configure_fit(self, server_round, parameters, client_manager):\n",
        "        config = {\"server_round\": server_round}\n",
        "        if self.global_metadata is not None and server_round > 1:\n",
        "            config.update({\n",
        "                \"quant_min\": float(self.global_metadata[\"min\"]),\n",
        "                \"quant_max\": float(self.global_metadata[\"max\"]),\n",
        "                \"quant_bits\": int(self.global_metadata[\"num_bits\"])\n",
        "            })\n",
        "\n",
        "        fit_ins = FitIns(parameters, config)\n",
        "        sample_size, min_num_clients = self.num_fit_clients(client_manager.num_available())\n",
        "        clients = client_manager.sample(num_clients=sample_size, min_num_clients=min_num_clients)\n",
        "        return [(c, fit_ins) for c in clients]\n",
        "\n",
        "    def aggregate_fit(self, server_round, results, failures):\n",
        "        print(f\"\\n=== [Servidor] Rodada {server_round} ===\")\n",
        "\n",
        "        if not results:\n",
        "            print(\"Nenhum resultado recebido\")\n",
        "            return None, {}\n",
        "\n",
        "        quantized_groups = []\n",
        "        num_examples_list = []\n",
        "        metadata_list = []\n",
        "\n",
        "        for client, fit_res in results:\n",
        "            cid = fit_res.metrics[\"cid\"]\n",
        "            acc = fit_res.metrics[\"accuracy\"]\n",
        "            loss = fit_res.metrics[\"loss\"]\n",
        "            is_quant = fit_res.metrics.get(\"quantized\", False)\n",
        "\n",
        "            print(f\"[Cliente {cid}] acc={acc:.4f} loss={loss:.4f} quant={is_quant}\")\n",
        "\n",
        "            params = parameters_to_ndarrays(fit_res.parameters)\n",
        "            num_weights = fit_res.metrics[\"num_weights\"]\n",
        "            num_initial = fit_res.metrics[\"num_initial\"]\n",
        "\n",
        "            # Separação enviada pelo cliente\n",
        "            w_final = params[:num_weights]\n",
        "            w_init  = params[num_weights:num_weights+num_initial]\n",
        "            grads   = params[num_weights+num_initial:]\n",
        "\n",
        "            # --- SALVA NAS ESTRUTURAS LOCAIS (opcional) ---\n",
        "            self.intercepted_weights[(server_round, cid)] = w_final\n",
        "            self.intercepted_initials[(server_round, cid)] = w_init\n",
        "            self.intercepted_gradients[(server_round, cid)] = grads\n",
        "\n",
        "            # --- SALVA NOS GLOBAIS VISÍVEIS AO NOTEBOOK ---\n",
        "            GLOBAL_WEIGHTS[(server_round, cid)] = w_final\n",
        "            GLOBAL_INITIALS[(server_round, cid)] = w_init\n",
        "            GLOBAL_GRADS[(server_round, cid)] = grads\n",
        "\n",
        "            # metadata (se existir)\n",
        "            if is_quant:\n",
        "                w_meta = {\n",
        "                    \"min\": fit_res.metrics[\"quant_min\"],\n",
        "                    \"max\": fit_res.metrics[\"quant_max\"],\n",
        "                    \"num_bits\": fit_res.metrics[\"quant_bits\"]\n",
        "                }\n",
        "            else:\n",
        "                w_meta = None\n",
        "\n",
        "            self.metadata_weights[(server_round, cid)] = w_meta\n",
        "            GLOBAL_METADATA[(server_round, cid)] = w_meta\n",
        "\n",
        "            num_examples = int(fit_res.num_examples)\n",
        "            num_examples_list.append(num_examples)\n",
        "\n",
        "            if is_quant:\n",
        "                metadata_list.append(w_meta)\n",
        "                # Converter de numpy -> torch (se precisar agregar como tensores)\n",
        "                w_final_t = [torch.from_numpy(x) if x is not None else None for x in w_final]\n",
        "                quantized_groups.append(w_final_t)\n",
        "            else:\n",
        "                metadata_list.append(None)\n",
        "                w_final_np = [np.array(x) for x in w_final]\n",
        "                quantized_groups.append(w_final_np)\n",
        "\n",
        "            # OPTIONAL: persistir imediatamente em disco (descomente para ativar)\n",
        "            # fname = os.path.join(PERSIST_DIR, f\"round{server_round}_client{cid}.pkl\")\n",
        "            # with open(fname, \"wb\") as fh:\n",
        "            #     pickle.dump({\"weights\": w_final, \"initial\": w_init, \"grads\": grads, \"meta\": w_meta}, fh)\n",
        "\n",
        "        # =====================================================\n",
        "        # AGREGAÇÃO\n",
        "        # =====================================================\n",
        "        if self.quantizer is not None and any(m is not None for m in metadata_list):\n",
        "            print(\"[Servidor] Agregando pesos QUANTIZADOS\")\n",
        "            agg_tensors = self.quantizer.aggregate_quantized(quantized_groups, num_examples_list)\n",
        "            self.global_metadata = metadata_list[0]\n",
        "            agg_numpy = [t.cpu().numpy() if t is not None else None for t in agg_tensors]\n",
        "        else:\n",
        "            print(\"[Servidor] Agregando pesos NÃO quantizados\")\n",
        "            agg_numpy = []\n",
        "            num_layers = len(quantized_groups[0])\n",
        "            total_w = sum(num_examples_list)\n",
        "            for layer_idx in range(num_layers):\n",
        "                acc_layer = None\n",
        "                for client_layer, n in zip(quantized_groups, num_examples_list):\n",
        "                    val = client_layer[layer_idx]\n",
        "                    if val is None:\n",
        "                        continue\n",
        "                    contrib = val * (n / total_w)\n",
        "                    acc_layer = contrib if acc_layer is None else acc_layer + contrib\n",
        "                agg_numpy.append(acc_layer)\n",
        "\n",
        "        new_params = ndarrays_to_parameters(agg_numpy)\n",
        "        return new_params, {}\n",
        "\n",
        "    def configure_evaluate(self, server_round, parameters, client_manager):\n",
        "        config = {\"server_round\": server_round}\n",
        "        if self.global_metadata is not None and server_round > 1:\n",
        "            config.update({\n",
        "                \"quant_min\": float(self.global_metadata[\"min\"]),\n",
        "                \"quant_max\": float(self.global_metadata[\"max\"]),\n",
        "                \"quant_bits\": int(self.global_metadata[\"num_bits\"])\n",
        "            })\n",
        "\n",
        "        evaluate_ins = EvaluateIns(parameters, config)\n",
        "        sample_size, min_num_clients = self.num_evaluation_clients(client_manager.num_available())\n",
        "        clients = client_manager.sample(num_clients=sample_size, min_num_clients=min_num_clients)\n",
        "        return [(c, evaluate_ins) for c in clients]\n",
        "\n",
        "    def aggregate_evaluate(self, server_round, results, failures):\n",
        "        if not results:\n",
        "            print(\"[Servidor] Nenhum cliente avaliou\")\n",
        "            return 0.0, {}\n",
        "        accs = [res.metrics[\"accuracy\"] for _, res in results]\n",
        "        mean_acc = sum(accs) / len(accs)\n",
        "        print(f\"[Servidor] Acurácia agregada na rodada {server_round}: {mean_acc:.4f}\")\n",
        "        return mean_acc, {}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuração da Simulação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ sys.path configurado — utils.py disponível\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-25 16:41:10,643\tINFO worker.py:1752 -- Started a local Ray instance.\n",
            "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=10, no round_timeout\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Ray inicializado no modo Notebook\n",
            "✓ Sem quantização (baseline)\n",
            "\n",
            "==============================\n",
            "Iniciando simulação FL\n",
            "==============================\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-25 16:41:18,109\tINFO worker.py:1752 -- Started a local Ray instance.\n",
            "2025-11-25 16:41:18,115\tINFO packaging.py:530 -- Creating a file package for local directory '.'.\n",
            "2025-11-25 16:41:18,116\tINFO packaging.py:358 -- Pushing file package 'gcs://_ray_pkg_0784d103fb0d9b54.zip' (0.09MiB) to Ray cluster...\n",
            "2025-11-25 16:41:18,118\tINFO packaging.py:371 -- Successfully pushed file package 'gcs://_ray_pkg_0784d103fb0d9b54.zip'.\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'CPU': 20.0, 'node:100.112.10.31': 1.0, 'GPU': 1.0, 'accelerator_type:G': 1.0, 'node:__internal_head__': 1.0, 'memory': 7743614976.0, 'object_store_memory': 3871807488.0}\n",
            "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 1}\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 20 actors\n",
            "\u001b[92mINFO \u001b[0m:      [INIT]\n",
            "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
            "\u001b[36m(pid=33161)\u001b[0m 2025-11-25 16:41:25.091307: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "\u001b[36m(pid=33161)\u001b[0m 2025-11-25 16:41:25.092486: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "\u001b[36m(pid=33161)\u001b[0m 2025-11-25 16:41:25.096055: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "\u001b[36m(pid=33161)\u001b[0m 2025-11-25 16:41:25.108213: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(pid=33161)\u001b[0m 2025-11-25 16:41:25.132475: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(pid=33161)\u001b[0m 2025-11-25 16:41:25.132532: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(pid=33161)\u001b[0m 2025-11-25 16:41:25.147106: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "\u001b[36m(pid=33161)\u001b[0m To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[36m(pid=33161)\u001b[0m 2025-11-25 16:41:26.485412: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n",
            "\u001b[92mINFO \u001b[0m:      Evaluating initial global parameters\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(ClientAppActor pid=33179)\u001b[0m Usando o dispositivo: cpu\n",
            "\u001b[36m(ClientAppActor pid=33179)\u001b[0m [Cliente 3] Device: cpu\n",
            "\u001b[36m(ClientAppActor pid=33179)\u001b[0m [Cliente 0] Device: cpu\n",
            "\u001b[36m(ClientAppActor pid=33179)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=33179)\u001b[0m [Cliente 0] FIT RODADA 1\n",
            "\u001b[36m(ClientAppActor pid=33179)\u001b[0m [Cliente 0] Gradientes capturados! Label: 0\n",
            "\u001b[36m(ClientAppActor pid=33179)\u001b[0m [Cliente 0] Fim Fit - Loss: 11.3144, Acc: 0.0000\n",
            "\u001b[36m(ClientAppActor pid=33179)\u001b[0m [Cliente 0] Retornando 30 parâmetros\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== [Servidor] Rodada 1 ===\n",
            "[Cliente 0] acc=0.0000 loss=11.3144 quant=False\n",
            "[Cliente 2] acc=0.0000 loss=11.1003 quant=False\n",
            "[Cliente 3] acc=0.0000 loss=16.3957 quant=False\n",
            "[Cliente 4] acc=0.0000 loss=2.0226 quant=False\n",
            "[Cliente 1] acc=0.0000 loss=36.7596 quant=False\n",
            "[Servidor] Agregando pesos NÃO quantizados\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Servidor] Acurácia agregada na rodada 1: 0.4139\n",
            "\u001b[36m(ClientAppActor pid=33176)\u001b[0m Usando o dispositivo: cpu\u001b[32m [repeated 4x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33177)\u001b[0m [Cliente 4] Device: cpu\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33177)\u001b[0m \u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33177)\u001b[0m [Cliente 4] FIT RODADA 2\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33177)\u001b[0m [Cliente 4] Gradientes capturados! Label: 2\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33175)\u001b[0m [Cliente 1] Fim Fit - Loss: 1.5707, Acc: 0.4379\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33175)\u001b[0m [Cliente 1] Retornando 30 parâmetros\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== [Servidor] Rodada 2 ===\n",
            "[Cliente 4] acc=0.4262 loss=1.5833 quant=False\n",
            "[Cliente 1] acc=0.4379 loss=1.5707 quant=False\n",
            "[Cliente 2] acc=0.4217 loss=1.5861 quant=False\n",
            "[Cliente 3] acc=0.4258 loss=1.5881 quant=False\n",
            "[Cliente 0] acc=0.4439 loss=1.5232 quant=False\n",
            "[Servidor] Agregando pesos NÃO quantizados\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Servidor] Acurácia agregada na rodada 2: 0.2792\n",
            "\u001b[36m(ClientAppActor pid=33176)\u001b[0m [Cliente 2] Device: cpu\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33177)\u001b[0m \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33177)\u001b[0m [Cliente 4] FIT RODADA 3\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33179)\u001b[0m [Cliente 1] Gradientes capturados! Label: 0\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33178)\u001b[0m [Cliente 3] Fim Fit - Loss: 1.4063, Acc: 0.4100\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33178)\u001b[0m [Cliente 3] Retornando 30 parâmetros\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== [Servidor] Rodada 3 ===\n",
            "[Cliente 4] acc=0.4234 loss=1.4085 quant=False\n",
            "[Cliente 1] acc=0.4304 loss=1.3183 quant=False\n",
            "[Cliente 2] acc=0.4242 loss=1.3982 quant=False\n",
            "[Cliente 0] acc=0.4457 loss=1.3624 quant=False\n",
            "[Cliente 3] acc=0.4100 loss=1.4063 quant=False\n",
            "[Servidor] Agregando pesos NÃO quantizados\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Servidor] Acurácia agregada na rodada 3: 0.3891\n",
            "\u001b[36m(ClientAppActor pid=33176)\u001b[0m [Cliente 4] Device: cpu\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33175)\u001b[0m \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33175)\u001b[0m [Cliente 0] FIT RODADA 4\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33177)\u001b[0m [Cliente 2] Gradientes capturados! Label: 3\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33178)\u001b[0m [Cliente 1] Fim Fit - Loss: 1.3435, Acc: 0.4174\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33178)\u001b[0m [Cliente 1] Retornando 30 parâmetros\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== [Servidor] Rodada 4 ===\n",
            "[Cliente 4] acc=0.4111 loss=1.3601 quant=False\n",
            "[Cliente 2] acc=0.4030 loss=1.3693 quant=False\n",
            "[Cliente 1] acc=0.4174 loss=1.3435 quant=False\n",
            "[Cliente 0] acc=0.4216 loss=1.3625 quant=False\n",
            "[Cliente 3] acc=0.3924 loss=1.4084 quant=False\n",
            "[Servidor] Agregando pesos NÃO quantizados\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Servidor] Acurácia agregada na rodada 4: 0.4042\n",
            "\u001b[36m(ClientAppActor pid=33177)\u001b[0m [Cliente 1] Device: cpu\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33177)\u001b[0m \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33177)\u001b[0m [Cliente 1] FIT RODADA 5\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33176)\u001b[0m [Cliente 3] Gradientes capturados! Label: 3\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33179)\u001b[0m [Cliente 2] Fim Fit - Loss: 1.3220, Acc: 0.4090\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33179)\u001b[0m [Cliente 2] Retornando 30 parâmetros\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== [Servidor] Rodada 5 ===\n",
            "[Cliente 4] acc=0.4040 loss=1.3519 quant=False\n",
            "[Cliente 3] acc=0.4046 loss=1.3304 quant=False\n",
            "[Cliente 2] acc=0.4090 loss=1.3220 quant=False\n",
            "[Cliente 1] acc=0.4145 loss=1.3308 quant=False\n",
            "[Cliente 0] acc=0.4203 loss=1.3459 quant=False\n",
            "[Servidor] Agregando pesos NÃO quantizados\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 6]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Servidor] Acurácia agregada na rodada 5: 0.4139\n",
            "\u001b[36m(ClientAppActor pid=33176)\u001b[0m [Cliente 2] Device: cpu\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33177)\u001b[0m \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33177)\u001b[0m [Cliente 4] FIT RODADA 6\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33177)\u001b[0m [Cliente 4] Gradientes capturados! Label: 2\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33177)\u001b[0m [Cliente 4] Fim Fit - Loss: 1.3213, Acc: 0.4171\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33177)\u001b[0m [Cliente 4] Retornando 30 parâmetros\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== [Servidor] Rodada 6 ===\n",
            "[Cliente 0] acc=0.4148 loss=1.3322 quant=False\n",
            "[Cliente 3] acc=0.4006 loss=1.3880 quant=False\n",
            "[Cliente 1] acc=0.4088 loss=1.3594 quant=False\n",
            "[Cliente 4] acc=0.4171 loss=1.3213 quant=False\n",
            "[Cliente 2] acc=0.4046 loss=1.3402 quant=False\n",
            "[Servidor] Agregando pesos NÃO quantizados\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 7]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Servidor] Acurácia agregada na rodada 6: 0.3903\n",
            "\u001b[36m(ClientAppActor pid=33177)\u001b[0m [Cliente 4] Device: cpu\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33175)\u001b[0m \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33175)\u001b[0m [Cliente 2] FIT RODADA 7\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33175)\u001b[0m [Cliente 2] Gradientes capturados! Label: 2\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33178)\u001b[0m [Cliente 0] Fim Fit - Loss: 1.3354, Acc: 0.4122\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33178)\u001b[0m [Cliente 0] Retornando 30 parâmetros\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== [Servidor] Rodada 7 ===\n",
            "[Cliente 3] acc=0.4032 loss=1.3436 quant=False\n",
            "[Cliente 4] acc=0.4142 loss=1.3363 quant=False\n",
            "[Cliente 0] acc=0.4122 loss=1.3354 quant=False\n",
            "[Cliente 2] acc=0.4090 loss=1.3321 quant=False\n",
            "[Cliente 1] acc=0.4133 loss=1.3288 quant=False\n",
            "[Servidor] Agregando pesos NÃO quantizados\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 8]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Servidor] Acurácia agregada na rodada 7: 0.3996\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[33m(raylet)\u001b[0m [2025-11-25 16:46:18,098 E 32044 32044] (raylet) node_manager.cc:2967: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 5d0a60fc9ddf34f7e2e82e309ad8614ca19161fbdbad54ea7534c65a, IP: 100.112.10.31) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 100.112.10.31`\n",
            "\u001b[33m(raylet)\u001b[0m \n",
            "\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
            "\u001b[36m(pid=33178)\u001b[0m 2025-11-25 16:41:26.472097: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "\u001b[36m(pid=33178)\u001b[0m 2025-11-25 16:41:26.484603: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\u001b[32m [repeated 38x across cluster]\u001b[0m\n",
            "\u001b[36m(pid=33178)\u001b[0m 2025-11-25 16:41:26.504342: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "\u001b[36m(pid=33178)\u001b[0m 2025-11-25 16:41:26.556574: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "\u001b[36m(pid=33178)\u001b[0m 2025-11-25 16:41:26.556629: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "\u001b[36m(pid=33178)\u001b[0m 2025-11-25 16:41:26.585538: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "\u001b[36m(pid=33178)\u001b[0m To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "\u001b[36m(pid=33173)\u001b[0m 2025-11-25 16:41:27.799154: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\u001b[32m [repeated 19x across cluster]\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(ClientAppActor pid=33179)\u001b[0m [Cliente 2] Device: cpu\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33177)\u001b[0m \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33177)\u001b[0m [Cliente 0] FIT RODADA 8\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33177)\u001b[0m [Cliente 0] Gradientes capturados! Label: 2\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33176)\u001b[0m [Cliente 3] Fim Fit - Loss: 1.3459, Acc: 0.4076\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33176)\u001b[0m [Cliente 3] Retornando 30 parâmetros\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== [Servidor] Rodada 8 ===\n",
            "[Cliente 2] acc=0.4157 loss=1.3278 quant=False\n",
            "[Cliente 3] acc=0.4076 loss=1.3459 quant=False\n",
            "[Cliente 1] acc=0.4275 loss=1.2915 quant=False\n",
            "[Cliente 4] acc=0.4273 loss=1.2999 quant=False\n",
            "[Cliente 0] acc=0.4413 loss=1.2634 quant=False\n",
            "[Servidor] Agregando pesos NÃO quantizados\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 9]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Servidor] Acurácia agregada na rodada 8: 0.4059\n",
            "\u001b[36m(ClientAppActor pid=33177)\u001b[0m [Cliente 2] Device: cpu\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33177)\u001b[0m \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33177)\u001b[0m [Cliente 2] FIT RODADA 9\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33177)\u001b[0m [Cliente 2] Gradientes capturados! Label: 2\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33176)\u001b[0m [Cliente 3] Fim Fit - Loss: 1.2878, Acc: 0.4316\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33176)\u001b[0m [Cliente 3] Retornando 30 parâmetros\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== [Servidor] Rodada 9 ===\n",
            "[Cliente 4] acc=0.4337 loss=1.3136 quant=False\n",
            "[Cliente 3] acc=0.4316 loss=1.2878 quant=False\n",
            "[Cliente 1] acc=0.4342 loss=1.2896 quant=False\n",
            "[Cliente 0] acc=0.4560 loss=1.2436 quant=False\n",
            "[Cliente 2] acc=0.4281 loss=1.3091 quant=False\n",
            "[Servidor] Agregando pesos NÃO quantizados\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 10]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Servidor] Acurácia agregada na rodada 9: 0.3735\n",
            "\u001b[36m(ClientAppActor pid=33177)\u001b[0m [Cliente 3] Device: cpu\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33177)\u001b[0m \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33177)\u001b[0m [Cliente 3] FIT RODADA 10\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33177)\u001b[0m [Cliente 3] Gradientes capturados! Label: 2\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33177)\u001b[0m [Cliente 3] Fim Fit - Loss: 1.2295, Acc: 0.4543\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=33177)\u001b[0m [Cliente 3] Retornando 30 parâmetros\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== [Servidor] Rodada 10 ===\n",
            "[Cliente 4] acc=0.4793 loss=1.2207 quant=False\n",
            "[Cliente 0] acc=0.4691 loss=1.2366 quant=False\n",
            "[Cliente 1] acc=0.4538 loss=1.2379 quant=False\n",
            "[Cliente 3] acc=0.4543 loss=1.2295 quant=False\n",
            "[Cliente 2] acc=0.4513 loss=1.2990 quant=False\n",
            "[Servidor] Agregando pesos NÃO quantizados\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
            "\u001b[92mINFO \u001b[0m:      Run finished 10 round(s) in 394.44s\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.41389473684210526\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.27915789473684216\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.38905263157894737\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 4: 0.40421052631578946\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 5: 0.4138947368421052\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 6: 0.3903157894736842\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 7: 0.3995789473684211\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 8: 0.40589473684210525\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 9: 0.3734736842105263\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 10: 0.37894736842105264\n",
            "\u001b[92mINFO \u001b[0m:      \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Servidor] Acurácia agregada na rodada 10: 0.3789\n",
            "\n",
            "✔ Simulação concluída com sucesso!\n",
            "\n",
            "==============================\n",
            "Gradientes disponíveis: 50\n",
            "Exemplo de chaves:\n",
            "[(1, 0), (1, 2), (1, 3), (1, 4), (1, 1)]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[33m(raylet)\u001b[0m [2025-11-25 18:07:18,260 E 32044 32044] (raylet) node_manager.cc:2967: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 5d0a60fc9ddf34f7e2e82e309ad8614ca19161fbdbad54ea7534c65a, IP: 100.112.10.31) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 100.112.10.31`\n",
            "\u001b[33m(raylet)\u001b[0m \n",
            "\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n"
          ]
        }
      ],
      "source": [
        "import sys, os\n",
        "import warnings\n",
        "import logging\n",
        "\n",
        "# ====================================================\n",
        "# FAZER O PYTHON ENXERGAR utils.py, run.py, load.py\n",
        "# ====================================================\n",
        "# Em notebook: SEMPRE usar o diretório do dataset / código\n",
        "project_root = \".\"   # <-- ONDE ESTÃO utils.py, load.py, run.py\n",
        "\n",
        "if project_root not in sys.path:\n",
        "    sys.path.append(project_root)\n",
        "\n",
        "print(\"✓ sys.path configurado — utils.py disponível\")\n",
        "\n",
        "# ====================================================\n",
        "# RAY — CONFIGURAÇÃO CORRETA PARA NOTEBOOK\n",
        "# ====================================================\n",
        "import ray\n",
        "\n",
        "# Evita conflitos de execução\n",
        "try:\n",
        "    ray.shutdown()\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# No notebook NÃO usar working_dir=os.getcwd() (quebra paths)\n",
        "ray.init(\n",
        "    ignore_reinit_error=True,\n",
        "    include_dashboard=False,\n",
        "    _system_config={\"automatic_object_spilling_enabled\": True}\n",
        ")\n",
        "\n",
        "print(\"✓ Ray inicializado no modo Notebook\")\n",
        "\n",
        "# ====================================================\n",
        "# SUPRIMIR WARNINGS\n",
        "# ====================================================\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "logging.basicConfig(level=logging.ERROR)\n",
        "\n",
        "# ==============================================\n",
        "# CONFIGURAÇÃO GERAL\n",
        "# ==============================================\n",
        "NCLIENTS        = 5\n",
        "NROUNDS         = 10\n",
        "NIID            = False\n",
        "DIRICHLET_ALPHA = 0.1\n",
        "FRACTION_FIT    = 1.0\n",
        "\n",
        "# ==============================================\n",
        "# QUANTIZAÇÃO\n",
        "# ==============================================\n",
        "ENABLE_QUANTIZATION = False\n",
        "QUANT_BITS = 8\n",
        "\n",
        "if ENABLE_QUANTIZATION:\n",
        "    quantizer = GradientQuantizer(QUANT_BITS)\n",
        "    print(f\"✓ Quantização ativa ({QUANT_BITS} bits)\")\n",
        "else:\n",
        "    quantizer = None\n",
        "    print(\"✓ Sem quantização (baseline)\")\n",
        "\n",
        "# ==============================================\n",
        "# CLIENTES\n",
        "# ==============================================\n",
        "def create_client(cid: str):\n",
        "    \"\"\"Construtor de clientes compatível com Flower Simulation\"\"\"\n",
        "    client = ClienteComQuantizacao(\n",
        "        cid              = int(cid),\n",
        "        niid             = NIID,\n",
        "        num_clients      = NCLIENTS,\n",
        "        dirichlet_alpha  = DIRICHLET_ALPHA,\n",
        "        quantizer        = quantizer,\n",
        "    )\n",
        "    return client.to_client()\n",
        "\n",
        "\n",
        "# ==============================================\n",
        "# SIMULAÇÃO\n",
        "# ==============================================\n",
        "ray_init_args = {\n",
        "    \"runtime_env\": {\n",
        "        \"working_dir\": \".\"\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "class Simulation:\n",
        "    def __init__(self):\n",
        "        self.strategy = ServidorComQuantizacao(\n",
        "            num_clients     = NCLIENTS,\n",
        "            dirichlet_alpha = DIRICHLET_ALPHA,\n",
        "            fraction_fit    = FRACTION_FIT,\n",
        "            quantizer       = quantizer,\n",
        "        )\n",
        "\n",
        "    def run(self):\n",
        "        fl.simulation.start_simulation(\n",
        "            client_fn     = create_client,\n",
        "            num_clients   = NCLIENTS,\n",
        "            client_resources={\"num_cpus\": 1},\n",
        "            config        = fl.server.ServerConfig(num_rounds=NROUNDS),\n",
        "            strategy      = self.strategy,    # <<-- USE ELA\n",
        "            ray_init_args = ray_init_args,\n",
        "        )\n",
        "        return self.strategy\n",
        "\n",
        "\n",
        "# ==============================================\n",
        "# EXECUÇÃO\n",
        "# ==============================================\n",
        "print(\"\\n==============================\")\n",
        "print(\"Iniciando simulação FL\")\n",
        "print(\"==============================\\n\")\n",
        "\n",
        "servidor = None\n",
        "\n",
        "try:\n",
        "    sim = Simulation()\n",
        "    servidor = sim.run()\n",
        "    print(\"\\n✔ Simulação concluída com sucesso!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"\\n❌ SIMULAÇÃO CRASHOU\")\n",
        "    print(f\"Erro: {type(e).__name__}: {str(e)}\")\n",
        "\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "    if sim and hasattr(sim, \"server\"):\n",
        "        servidor = sim.server\n",
        "        print(\"\\nDados capturados (parciais):\")\n",
        "        # Corrigido: intercepted_gradients é o nome correto\n",
        "        print(f\"- Gradientes capturados: {len(servidor.intercepted_gradients)}\")\n",
        "\n",
        "finally:\n",
        "    print(\"\\n==============================\")\n",
        "    if servidor:\n",
        "        print(f\"Gradientes disponíveis: {len(servidor.intercepted_gradients)}\")\n",
        "        if servidor.intercepted_gradients:\n",
        "            print(\"Exemplo de chaves:\")\n",
        "            print(list(servidor.intercepted_gradients.keys())[:5])\n",
        "    else:\n",
        "        print(\"⚠ Nada foi capturado\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# 🔒 SEÇÃO: ATAQUE DLG (Deep Leakage from Gradients)\n",
        "\n",
        "Demonstra vulnerabilidade de privacidade: reconstrução de dados privados a partir de gradientes compartilhados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Preparação: Extrair Dados Reais para Comparação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "SELEÇÃO DE ALVO PARA ATAQUE DLG (FOCADO NA RODADA 1)\n",
            "============================================================\n",
            "✓ Alvo vulnerável encontrado na Rodada 1!\n",
            "\n",
            "🎯 Alvo selecionado:\n",
            "   - Cliente: 0\n",
            "   - Rodada: 1\n",
            "\n",
            "📊 Gradientes interceptados: 10 tensores\n",
            "   - Status: sem quantização (baseline)\n",
            "\n",
            "📦 Pesos iniciais interceptados: 10 tensores\n",
            "[Cliente 0] Device: cuda\n",
            "\n",
            "✓ Imagem real carregada:\n",
            "   - Shape: torch.Size([1, 3, 32, 32])\n",
            "   - Label: 0\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAGrCAYAAADn6WHYAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjUsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvWftoOwAAAAlwSFlzAAAPYQAAD2EBqD+naQAALNRJREFUeJzt3XmUVPWd9/FvVXV1VXV1dzVLs0M3NMhOfMTEBKLtCiKMmhjRyTACbmQOxkRFSZxRoyiaGAlMZjIjmpEMwWRinGPik8UZRhwzLkkUcYCEiIDIJjS977X9nj/yUIeyQeoDP4PG9+ucnBMv37p169a99albVXwIOOecAQBwgoInewMAAH8eCBQAgBcECgDACwIFAOAFgQIA8IJAAQB4QaAAALwgUAAAXhAoAAAvCBR8oM2bN8+qq6sLms1mszZhwgS77777jvv+qqurbd68ebn/fu655ywQCNhzzz133OvEB8u7n+MT9c///M82bNgw6+7u9rbOD6uPdKCsWrXKAoGAvfLKKyd7Uz7QqqurLRAI5P4Xj8ftE5/4hP3rv/7ryd60PD/4wQ9s165ddsMNN/T4s23bttmCBQtsxIgRFo1Grby83KZOnWorVqywzs7Ok7C1+ZYuXWpPPfXU+7LuF1980T796U9bSUmJDRgwwG688UZra2s77vWdffbZecdDLBazSZMm2fLlyy2bzXrc8pPr3/7t32zOnDk2atQoCwQCdvbZZx9xbt68eZZMJu3hhx/+027gB1DRyd4AfDiceuqpdsstt5iZ2b59++zRRx+1uXPnWnd3t1133XUneev+6MEHH7Qrr7zSEolE3vKf/exndvnll1skErGrrrrKJkyYYMlk0v7nf/7Hbr31Vtu8ebOtXLnyiOs866yzrLOz04qLi9/XbV+6dKl97nOfs0svvdTrejds2GDnnXeejR071pYtW2a7d++2b37zm7Z161b7xS9+cdzrHTJkiN1///1mZnbw4EF7/PHH7aabbrK6uroTukL8IPmnf/one/XVV+3jH/+41dfXH3UuGo3a3LlzbdmyZfbFL37RAoHAn3ArP2DcR9hjjz3mzMz99re/Pdmb8oFWVVXlZs6cmbfswIEDrrS01I0dO/Z9ve+5c+e6qqqqY86tX7/emZlbu3Zt3vLt27e70tJSN2bMGLd3794et9u6datbvnx57r+rqqrc3LlzT3SzZfF4/H253xkzZriBAwe65ubm3LJHHnnEmZl75plnjmudtbW1bvz48XnLOjs7XVVVlSsrK3PpdPqEtvn9Vuhz/Pbbb7tMJuOcc278+PGutrb2qLOvvPKKMzP3X//1X5628sPpI/2R15HMmzfPSktL7e2337ZZs2ZZaWmpDR482P7xH//RzMw2btxo5557rsXjcauqqrLHH3887/YNDQ22aNEimzhxopWWllp5ebnNmDHDXn/99R73tXPnTrv44ostHo9bv3797KabbrJnnnnmiJ/Z//rXv7YLL7zQEomElZSUWG1trb3wwgt5M1/72tcsEAjYG2+8YXPmzLFEImGVlZV2xx13mHPOdu3aZZdccomVl5fbgAED7KGHHjru/VRZWWljxoyxbdu25S3PZrO2fPlyGz9+vEWjUevfv78tWLDAGhsb8+Z+8pOf2MyZM23QoEEWiUSspqbGlixZYplM5ri256mnnrLi4mI766yz8pZ/4xvfsLa2Nvvud79rAwcO7HG7kSNH2pe+9KWjrvdo36Eoz8ebb75p8+bNs4qKCkskEjZ//nzr6OjIzQUCAWtvb7fvfe97uY+RDv+Mf8+ePXb11Vdb//79LRKJ2Pjx4+1f/uVfjrlPWlpa7D//8z9tzpw5Vl5enlt+1VVXWWlpqf3oRz865joKFY1G7eMf/7i1trbagQMHcsvT6bQtWbLEampqLBKJWHV1td1+++09vm8IBAL2ta99rcd63/19x6GPqV944QW7+eabrbKy0uLxuH3mM5+xurq6vNs65+zee++1IUOGWElJiZ1zzjm2efPmgh/T0KFDLRgs7CVy8uTJ1rt3b/vJT35S8Pr/HBEoR5DJZGzGjBk2dOhQ+8Y3vmHV1dV2ww032KpVq+zCCy+0008/3b7+9a9bWVmZXXXVVbZjx47cbbdv325PPfWUzZo1y5YtW2a33nqrbdy40Wpra23v3r25ufb2djv33HNt7dq1duONN9rf/u3f2osvvmiLFy/usT3PPvusnXXWWdbS0mJ33XWXLV261Jqamuzcc8+13/zmNz3mr7jiCstms/bAAw/YGWecYffee68tX77cLrjgAhs8eLB9/etft5EjR9qiRYvs+eefP659lE6nbffu3darV6+85QsWLLBbb7019/3E/Pnzbc2aNTZ9+nRLpVK5uVWrVllpaandfPPNtmLFCps8ebLdeeed9pWvfOW4tufFF1+0CRMmWDgczlv+9NNP24gRI2zKlCnHtd4jUZ+P2bNnW2trq91///02e/ZsW7Vqld199925P1+9erVFIhE788wzbfXq1bZ69WpbsGCBmZnt37/fPvnJT9ratWvthhtusBUrVtjIkSPtmmuuseXLl7/ndm7cuNHS6bSdfvrpecuLi4vt1FNPtddee+3Ed8Zh3nrrLQsEAlZRUZFbdu2119qdd95pp512mn3rW9+y2tpau//+++3KK688ofv64he/aK+//rrddddd9jd/8zf29NNP9/ju7M4777Q77rjDPvaxj9mDDz5oI0aMsGnTpll7e/sJ3ffRnHbaaT3eVHzknOxLpJPpSB95zZ0715mZW7p0aW5ZY2Oji8ViLhAIuB/+8Ie55Vu2bHFm5u66667csq6urtxl8iE7duxwkUjE3XPPPbllDz30kDMz99RTT+WWdXZ2ujFjxjgzc+vWrXPOOZfNZt2oUaPc9OnTXTabzc12dHS44cOHuwsuuCC37K677nJm5q6//vrcsnQ67YYMGeICgYB74IEHejymQi79q6qq3LRp01xdXZ2rq6tzGzdudH/913/tzMwtXLgwN/erX/3KmZlbs2ZN3u1/+ctf9lje0dHR434WLFjgSkpKXFdXV25ZoR95DRkyxF122WV5y5qbm52ZuUsuueSYtz/k3R+HrFu37oSfj6uvvjrvPj7zmc+4Pn365C072kde11xzjRs4cKA7ePBg3vIrr7zSJRKJI+7HQ5544glnZu7555/v8WeXX365GzBgwFFv+15qa2vdmDFjcsfDli1b3K233urMLO+j0Q0bNjgzc9dee23e7RctWuTMzD377LO5Ze8+jw559/Nx6Jw9//zz8/b/TTfd5EKhkGtqanLO/fEj2eLiYjdz5sy8udtvv92Zmfzx4rE+8nLOueuvv97FYjFpvX9uuEI5imuvvTb3/ysqKmz06NEWj8dt9uzZueWjR4+2iooK2759e25ZJBLJXSZnMhmrr6+30tJSGz16tK1fvz4398tf/tIGDx5sF198cW5ZNBrt8QX3hg0bbOvWrfb5z3/e6uvr7eDBg3bw4EFrb2+38847z55//vkev6w5fNtDoZCdfvrp5pyza665psdjOnzb38t//Md/WGVlpVVWVtrEiRNt9erVNn/+fHvwwQdzM0888YQlEgm74IILctt58OBBmzx5spWWltq6detys7FYLPf/W1tb7eDBg3bmmWdaR0eHbdmypaBtOlx9fX2Pq6WWlhYzMysrK5PXdzTH83x84QtfyPvvM8880+rr63PbdzTOOXvyySftL/7iL8w5l7dPp0+fbs3NzXnH1Lsd+vVaJBLp8WfRaPSEft22ZcuW3PEwZswYe/DBB+3iiy+2VatW5WZ+/vOfm5nZzTffnHfbQz/u+NnPfnbc93/99dfnffl95plnWiaTsZ07d5qZ2dq1ay2ZTPb4kvzLX/7ycd/nsfTq1cs6OzvzPs78qOFXXkcQjUatsrIyb1kikbAhQ4b0+AVHIpHI+34gm83aihUr7Dvf+Y7t2LEj7zuBPn365P7/zp07raampsf6Ro4cmfffW7duNTOzuXPnHnV7m5ub815Mhw0b1mMbo9Go9e3bt8fy9/r1yuEOfXSWyWRs06ZNdu+991pjY2Per5+2bt1qzc3N1q9fvyOu4/DP1jdv3mx/93d/Z88++2yPF9bm5uaCtund3Lv+8dFD3xu0trYe1/qOxMfzcejPGhsb877beLe6ujpramqylStXHvVXaIfv03c7FNpH+vsRXV1deaGuqq6utkceecSy2axt27bN7rvvPqurq7NoNJqb2blzpwWDwR7H9IABA6yioiL34n883mufHrpvM7NRo0blzVVWVvZ44+HLoePvo/wrLwLlCEKhkLT88BeypUuX2h133GFXX321LVmyxHr37m3BYNC+/OUvH9dv9A/d5sEHH7RTTz31iDOlpaXH3M5Ctv299O3b184//3wzM5s+fbqNGTPGZs2aZStWrMi9A81ms9avXz9bs2bNEddxKKSbmpqstrbWysvL7Z577rGamhqLRqO2fv16W7x48XHtpz59+vT44r+8vNwGDRpkmzZtktd3NL6eD7Nj7/tD9zVnzpyjBtikSZOOevtDP0LYt29fjz/bt2+fDRo06D3v/73E4/Hc8WBmNnXqVDvttNPs9ttvt7//+7/Pmz2RF9ij/UjjRI/n90NjY6OVlJScUFB/2BEonv34xz+2c845x7773e/mLW9qasq7QqiqqrLf/e535pzLO+HefPPNvNvV1NSY2R9fHA8/gU+2mTNnWm1trS1dutQWLFhg8XjcampqbO3atTZ16tT3PKmee+45q6+vt3//93/P+1XW4T9uUI0ZM+aIt581a5atXLnSXnrpJfvUpz513Os/5P16Po70oltZWWllZWWWyWSO674mTJhgRUVF9sorr+R9VJtMJm3Dhg15y07UpEmTbM6cOfbwww/bokWLbNiwYVZVVWXZbNa2bt1qY8eOzc3u37/fmpqarKqqKresV69e1tTUlLfOZDJ5xDAsxKF1b9261UaMGJFbXldX1+ONhy87duzIe5wfRXyH4lkoFOrxLumJJ56wPXv25C2bPn267dmzx37605/mlnV1ddkjjzySNzd58mSrqamxb37zm0f8283v/qnkn9LixYutvr4+t82zZ8+2TCZjS5Ys6TGbTqdzLxiH3l0evp+SyaR95zvfOe5t+dSnPmWbNm3q8fHObbfdZvF43K699lrbv39/j9tt27bNVqxYUfD9vF/PRzwe7/GCGgqF7LLLLrMnn3zyiFdZx7qvRCJh559/vn3/+9/P+9hv9erV1tbWZpdffvlxbevR3HbbbZZKpWzZsmVmZnbRRReZmfX4NdqhP585c2ZuWU1NTY9fHK5cufK4f0Z+/vnnWzgctm9/+9t5x9mxfhl3ItavX+/114QfRlyheDZr1iy75557bP78+TZlyhTbuHGjrVmzJu9dktkff177D//wD/aXf/mX9qUvfckGDhxoa9asyX0GfegdazAYtEcffdRmzJhh48ePt/nz59vgwYNtz549tm7dOisvL7enn376T/44zcxmzJhhEyZMsGXLltnChQuttrbWFixYYPfff79t2LDBpk2bZuFw2LZu3WpPPPGErVixwj73uc/ZlClTrFevXjZ37ly78cYbLRAI2OrVq0/o44pLLrnElixZYv/93/9t06ZNyy2vqamxxx9/3K644gobO3Zs3t+Uf/HFF+2JJ56Qep3er+dj8uTJtnbtWlu2bJkNGjTIhg8fbmeccYY98MADtm7dOjvjjDPsuuuus3HjxllDQ4OtX7/e1q5daw0NDe+53vvuu8+mTJlitbW1dv3119vu3bvtoYcesmnTptmFF16YNxsIBKy2tva4e8vGjRtnF110kT366KO5n+vOnTvXVq5cmfuY8ze/+Y1973vfs0svvdTOOeec3G2vvfZa+8IXvmCXXXaZXXDBBfb666/bM8880+N7v0JVVlbaokWL7P7777dZs2bZRRddZK+99pr94he/KHidzz//fC7k6urqrL293e69914z+2ODwuFX16+++qo1NDTYJZdcclzb+2fjZPy07IPiaD8bjsfjPWaP9LeDnev5t8i7urrcLbfc4gYOHOhisZibOnWqe+mll1xtbW2Pnx1u377dzZw508ViMVdZWeluueUW9+STTzozcy+//HLe7GuvveY++9nPuj59+rhIJOKqqqrc7Nmz8/5m7qGfqdbV1eXdVn1Mx3qMh1u1apUzM/fYY4/llq1cudJNnjzZxWIxV1ZW5iZOnOhuu+22vL+p/sILL7hPfvKTLhaLuUGDBrnbbrvNPfPMM3k/0T207YX8bNg55yZNmuSuueaaI/7ZG2+84a677jpXXV3tiouLXVlZmZs6dar79re/nfcz5WP9bPiQE3k+Dh13O3bsyC3bsmWLO+uss1wsFuvxs9b9+/e7hQsXuqFDh7pwOOwGDBjgzjvvPLdy5cqC9suvfvUrN2XKFBeNRl1lZaVbuHCha2lpyZtpbW11ZuauvPLKY67vvY6b5557Lu8nwKlUyt19991u+PDhLhwOu6FDh7qvfvWrefvcOecymYxbvHix69u3ryspKXHTp093b7755lF/NvzudosjPU+ZTMbdfffduXPx7LPPdps2bSr4b8ofev6O9L93/8R58eLFbtiwYXk/Uf4oCjh3Er/FQg/Lly+3m266yXbv3m2DBw8+2ZvzobJ69WpbuHChvf3223l/uQ7H9vOf/9xmzZplr7/+uk2cOPFkb86HSnd3t1VXV9tXvvKV92xd+CjgO5ST6N1/D6Crq8sefvhhGzVqFGFyHP7qr/7Khg0blqvJQeHWrVtnV155JWFyHB577DELh8M9/r7RRxFXKCfRjBkzbNiwYXbqqadac3Ozff/737fNmzfbmjVr7POf//zJ3jwAkPCl/Ek0ffp0e/TRR23NmjWWyWRs3Lhx9sMf/tCuuOKKk71pACDjCgUA4AXfoQAAvCBQAABeECgAAC8K/lJ+y2btH+Mpetc/dHTM+SLt3+xW58NF2u8PAkGx0E6cd6Z9daV+0xUQ/2UCl9XuICtukPpV3fs9r1Z6uKxeARIUSxGLw9oxqv4792nxMXceoaX4vaS6u6R5E4859SRIZdLSfFJ8vjLi5h/+D8wVIp3W5kMhbfvVEtapn5h6zBmuUAAAXhAoAAAvCBQAgBcECgDACwIFAOAFgQIA8IJAAQB4QaAAALwgUAAAXhAoAAAvCBQAgBcFlwf9+kDnsYcOEwxqPUCBkNZjVBrQem7KOxql+VRKK+pJVgyQ5rPRMmk+GApJ82oXWSCorV/tLjOxZygg9ioFAuJ7o4DWNWcmPl4zMyc+hm7xPsTqLLUPrkjcR/3D2ga5VFKaD4W07qlUUlt/ICj232W07ck6bXucad1rbe1i95rYLVYIrlAAAF4QKAAALwgUAIAXBAoAwAsCBQDgBYECAPCCQAEAeEGgAAC8IFAAAF4QKAAALwgUAIAXBRdofXl7QlpxVuwNColdSWeF66X5T+17Q5rf8Ydd0vze8oHS/MZTPinNt5T1luZdVtufTuzCCgTEJ1h87xLKaj1JTtyebOGH/v+f13qVzMycWJ4lt4WJT0FAvIexkQZp/jPxTdJ8skU7hxN9I9J864EWaX7gAO0ca2jTurmySW3/Z7u1Yy7ZpR0QkbS2PRedf+wZrlAAAF4QKAAALwgUAIAXBAoAwAsCBQDgBYECAPCCQAEAeEGgAAC8IFAAAF4QKAAALwgUAIAXBRcatYe07qOUWOYVErOtMSn23PQdJ82fPnKKNN+r5Q/S/I+3vCzNvzzsdGm+rLRcmu8MhKT5NrELa3i4U5ofV9Qhzb/VrK3/V8VDpPlkUNs/ZmYmdnnJ1MI8cTyd0W5QV9ctzYfFbrFoMi3NR6xCmu8+IPbNxaRxS3QWS/Mtddox3dyldYu1upQ0XwiuUAAAXhAoAAAvCBQAgBcECgDACwIFAOAFgQIA8IJAAQB4QaAAALwgUAAAXhAoAAAvCBQAgBcFFzJlQ1qXUaBI6+lxTpt/0yWk+Y+1bZPmTx8Yl+Zj4V7S/OjB2v4ccmCTNF87fKI0X1wWlebT2tNlMdcuzb/wqvZ8bRW7uUKlEWm+OKD3comHtGXF7q9MVlt/UOz+yrqwNJ8q1s7JUEZ7P9vVqHVPndKunZOuQ3vCMmHtGAqI+z+WFc/JTJs0r1bBFYIrFACAFwQKAMALAgUA4AWBAgDwgkABAHhBoAAAvCBQAABeECgAAC8IFACAFwQKAMALAgUA4EXBXV6Ty2PSit9KJqX57ow0bp1FWm/Qqy2l0vyA3/9emq8aOEiaH1dZLs13JbT9n2lukeYjRVpvU9+iLmn+8d++Ic3/svJUab6jdIA0XxnQ3ktlTSzOMjMzrRsqGdDuo0urg7NUSCtv2p2pkOa3u4HS/JCI1oU1sLtBmm9s1l6D0ilt/7dkWqX5T5efIs13pzql+UiRtj+jhb/8F4wrFACAFwQKAMALAgUA4AWBAgDwgkABAHhBoAAAvCBQAABeECgAAC8IFACAFwQKAMALAgUA4EXhXV4l2orHRYul+fZUSprPpNPSfLpqpDSf7dB6fT49PC7N72trk+a727Tt6VumdX8dfHWdNL8rVibN74hXS/PBcq0bLWpaT1VWq9ky597/914xsftLewbMsuL6g0Va19Pe0FBpvjxWIc13h7TCv3S8SZpvbdb66SrKtH7AQEArXws7rV8voZ0CVp/WusIKwRUKAMALAgUA4AWBAgDwgkABAHhBoAAAvCBQAABeECgAAC8IFACAFwQKAMALAgUA4AWBAgDwouCynoNJbcV9tNoa61Ok3SCeapTmu7o7pPlhpVqPUXGF1uszpLfWxFT31k5pvjimvVeIjZ4kzb/wO217OuNaD1PYtPmQ07rOsqYdby5wPO+9xMKwgDgv9pepQmJ/WTagFf7tTEak+bJoizQ/qJ/WzdVQNkCaDwW1/sF3usSusID2/L7esEea3x9sluavKGCGKxQAgBcECgDACwIFAOAFgQIA8IJAAQB4QaAAALwgUAAAXhAoAAAvCBQAgBcECgDACwIFAOBFwYVVrWltxe1prVupd7GWbf1Ltd6dcFzr0YkXvSPNp8RuqJKQ9nhrxo6S5kMhrReqqKxdmq94R+sBGpHslOZdww5pviNULM13l1dK89lgTJo/Hk6t8hKJ1VBWFNSO0bDYXVYU1J6zJusvzSfFt8udvbVjop/7X2m+qZd2zrQ0an12bZFuaX5khfYaWgiuUAAAXhAoAAAvCBQAgBcECgDACwIFAOAFgQIA8IJAAQB4QaAAALwgUAAAXhAoAAAvCBQAgBcFd3mF1CIg07q8Wru0rq1kWuutiSQbpfnJFVq3VeOBFmk+XB6X5jNpbXu6ulPSfGubtj9bmtuk+YqE1pPUOxKW5vuK3Vzp4hJpvj2rv/dKiqeME8+ZlNP64zJi31yRaQ9Ang9q8+2BhDTfWaKdY8OLtL658RXaMfROi/YacSAgvqaktGO0vLPgl/+CcYUCAPCCQAEAeEGgAAC8IFAAAF4QKAAALwgUAIAXBAoAwAsCBQDgBYECAPCCQAEAeEGgAAC8KLzLKxjQ1tydlMZDaa23Jmha11OmqFiaH9ZfW39rg9Zt9ca2Zml+aElami+PSeO2O1MqzTf1jkrz+zPie5ew1pMUbGuQ5qOuXpqP9e4nzZuZxUq0fRoR3991i11hXVntHO5Ka91iXU7boIzY/aWOm/gaMSypdXn1+YO2/jrxJbS9XnuN6JvsJc03Z7X+xEJwhQIA8IJAAQB4QaAAALwgUAAAXhAoAAAvCBQAgBcECgDACwIFAOAFgQIA8IJAAQB4QaAAALwouMsrEtCyJxvVeowsEJfGU2JvUElXozTf0NIkzQ+vTEjzmzu0nqRf79R6fQbEUtL8/u52aX5vn1HSfCil9SSFsh3SfKZ3lTSfzGak+YCJRUxmlkxq/WsBp91HWOzXi4jz4bB2zkfF96dF4i4tEs95J5Z/VWiHnDU2aDeoD3dL88k6bfuHlfWV5ou7tD6+QnCFAgDwgkABAHhBoAAAvCBQAABeECgAAC8IFACAFwQKAMALAgUA4AWBAgDwgkABAHhBoAAAvCi4y6soJBbviL07AW3cXEbrxYkktd6dikRMmh8+qEyaDxZrPU/1LdrjjUa1brT+RW3S/N5ibf+kSvtI84G2Omk+mOzS5qPa8+XE49nMTGtrMxOrvCwlblJXRjwnxfebAXX7xZO+SNyjTuwuezsQlua7i7UurF6V/aT5WHfBL89mZtYvrfUJbmjZJ80XgisUAIAXBAoAwAsCBQDgBYECAPCCQAEAeEGgAAC8IFAAAF4QKAAALwgUAIAXBAoAwAsCBQDgRcFlMWViL07AxGIfsdfHFWldUvGA1m1VUZyS5kNi11O8KCTNlxdr2V9ZJPY2FWm9QY0hrTursUjb/4EKrfdILsISx7PH0eWlcvL7O/WcFNf+/p7Cpr6fzYp3EEhr/XcB8Zh2VQOl+Umj+kvzjeW7pfnu32n9d/XpZmm+EFyhAAC8IFAAAF4QKAAALwgUAIAXBAoAwAsCBQDgBYECAPCCQAEAeEGgAAC8IFAAAF4QKAAALwoucKqMaivOir0+4aCWbcXZtDQ/ukzrzqrqVyLNW1brDep22uMtCWk7tD2ZkeaHVGhdW58OtUnzr2SLpflMLCHNq++MsuJ8V0Z/7+XE9qwicT6kdm2J8yHxIQfVvj/1NaJT656aWN4izY8u07Y/Ku6g1m6ta6tidLW2/pD2mlXdW+suKwRXKAAALwgUAIAXBAoAwAsCBQDgBYECAPCCQAEAeEGgAAC8IFAAAF4QKAAALwgUAIAXBAoAwIuCu7wmJGLSirsyWteW3P3VpvX0TBmklZGFwwXvGjMzc52d0nx7e0qajxVpO6g6oc2nxZ6neFS7weRMgzS/K6wdb5FomTTvxAOuNaUdz2ZmGfE+gmKfXdaJ61e7wsRuLjPxmEtp58ApEa0/rrhbe85+urVVmj+lj9adNXGw1mfX3q11lw37xBhpvsqNlOYLwRUKAMALAgUA4AWBAgDwgkABAHhBoAAAvCBQAABeECgAAC8IFACAFwQKAMALAgUA4AWBAgDwouDCqu0tWo9OMKD1AKm9RIMDWg9Qd0e3NN8eDEvz0YC2/dFgRpr/+EBtf0bT2v55q117b1HXpvUSjemn7c/6xnek+X1prXstFo5I82rXnJlZVuy2clmte0pt2sqIt0imtO3PWFaaT7Vp/W59Eklp/kev75Hm+0W0Y+Lnv9e6ttLZftL8KYOkcYuEtecrUhTX7qAAXKEAALwgUAAAXhAoAAAvCBQAgBcECgDACwIFAOAFgQIA8IJAAQB4QaAAALwgUAAAXhAoAAAvCBQAgBcFN+q9cLBJWnFAbNMLicV103ppRXo7D2rlkC4YleYri7XHO6hE256DbV3S/OZWrYxxeKVWjLfzoPZeJCyWhY4u1/bns/u0or5kUYk0L3Z/mpmZEwtPA2KZZEbcqFRWKyTNOq3s0YnbX5bUjukLSrXC0wER7RwYXBqS5t+o116D/ndvizRf1Vc7Jy2p7Z9gOKatv5B1el8jAOAjiUABAHhBoAAAvCBQAABeECgAAC8IFACAFwQKAMALAgUA4AWBAgDwgkABAHhBoAAAvCi4y+vVpNYrUyRmVTyg9QxdEExK84G01ht0sFnrnupVrG1P2LVK8/VaTY91FWu9RL0SWnfZgdZOaT4kdnn1jWs9TJ0pbXv2ZOPSfNpp229mlhK7sJJi91eXuE+7s9oxETDtOVD72oIZ7TXilP0N0vwnemvb89t3tNegjqQ235TWnt/2tHb8pMT+xJh+SB8TVygAAC8IFACAFwQKAMALAgUA4AWBAgDwgkABAHhBoAAAvCBQAABeECgAAC8IFACAFwQKAMCLgru8GlNar0xI7CVqd2lpvq1LK7eKl2jbv31/izQ/YYTWdRbQqr+spVvL/mF9tG6ucJHW21Qc0p6vjpRWHBTTdqcNDWtdXs92aNvfHdDfe6XFLq9MQDtn1H4xJ25PKKPNh8VzeEyyTppvaNouzR9oflOar+jS9uewAWOl+cF9E9J8Nqh1r4kv0ZYSn99Y+NjbwxUKAMALAgUA4AWBAgDwgkABAHhBoAAAvCBQAABeECgAAC8IFACAFwQKAMALAgUA4AWBAgDwouAur2S31p1lWi2RdWvj9na7tj2lvbXs3L61WZpvGxyT5kNpbXt2N2vz4yvEHiaxR6okqK1/V5M2X5nVHu+lA4ql+We3NEjzm9Nxad7MLBUS36+JXVuW0bqnirJa11ap086xczrfkuYvzGyU5suyB6T5TKl2TEfE/TOuPCPN9+pbIs2HQtr6A+KraEentn/Ko72OOcMVCgDACwIFAOAFgQIA8IJAAQB4QaAAALwgUAAAXhAoAAAvCBQAgBcECgDACwIFAOAFgQIA8KLgLi/r1npuVAGtlsj2tWu9R5Fw4Q/VzCyV0nqMtjZq+6d3KCTNt4u7vzig9QB1pbUnoLEjKc3//p1Wab68pL80P6GXtj9XTtIe7w/+sFeaNzPbkdK6m5q6tW3aJp4DlQmtj+yzNdpzUCO8nJiZRQ5qx1A6UyXNB9q1bqvQQK2Pb2hVjTTfJb6GlpVGpfmSIm1/ZsXuMjO6vAAAfyIECgDACwIFAOAFgQIA8IJAAQB4QaAAALwgUAAAXhAoAAAvCBQAgBcECgDACwIFAOBF4eU7Ka33JaCWc5mTpt9o0ubbxNqaPnGtR+e3u7WuqnOHl0rzkUCHNJ+IRKT5XU1ad9k7LV3SfLO2ekt1a+vv6tS6vEZFw9L84rFaL5eZ2ctvt0jz+7Ll0nxHL22nJk3bnsqUdo4FExXSfHTUFGk+HtLe/6Y6xMfbpZ1jrZ3a/o8Fta6txJAR0ny6ROtqKzL1NfrYuEIBAHhBoAAAvCBQAABeECgAAC8IFACAFwQKAMALAgUA4AWBAgDwgkABAHhBoAAAvCBQAABeFN7l1an10JjY5eXEXpm3tZohW1/XKc2P7K/14vx0U4M0f0qF1hUWC2Sl+YjY5bVzn9ad1d6lHQ8NnVqZ2v5WrScpI3Z/Vca1Lq+hicJPlUMGR7RjetVLu6T5tNhtNbJXTJrPtnRL862RJmk+EdP614pC2v7MpLVjriigvagk4tr+Hz5htDRfGi+T5oNB/91cKq5QAABeECgAAC8IFACAFwQKAMALAgUA4AWBAgDwgkABAHhBoAAAvCBQAABeECgAAC8IFACAFwUXFAXf9y4vTXtQu8X/3aF1PX11ktblVRIrkebXvrFfmp/cT8v+VGCgNN/U2i7Nt3dq3WiNXVp31v527fl9+6DWOzVxoNbNVRnReqHMzAaXa31qY4aWS/MtxX2l+cG9tf64/uVa11YkpR1DTfVt0vy2Ru016JSKjDTfa6B2zoweOUKaL41rrxFh8TVU7SKTX3QLwBUKAMALAgUA4AWBAgDwgkABAHhBoAAAvCBQAABeECgAAC8IFACAFwQKAMALAgUA4AWBAgDwouBCo/lj+kgrXrujUZp/uyMlzatefkeb3ztc6/7qXaJ1Q73erPUqvVTfKs3/n3Ztf2bSWWn+QJvWndWY1rq8drZpvU0pbXNsRFp7L5XMaL1QZmZFRVoX1qUjtK6n1j79pPldLdpjGFLdX5pPRLTneOP2Omm+eUe9ND+4Wjsne/fqLc0notrjDTutDy6Q1bq8VPraj308c4UCAPCCQAEAeEGgAAC8IFAAAF4QKAAALwgUAIAXBAoAwAsCBQDgBYECAPCCQAEAeEGgAAC8KLjs5oyBCWnFBxs7pPlhJRFpPhbRmmiirliaT6WapflIUOttqukbl+Zdcak039SmdXklO9uk+ZZOrTyrw5VJ8+80avt/UKJcmk857fhpTmnPr5lZkdgXFgloz1koJo1bW0Y7B3prVVVWGtK2f+Jg7QF8bMAQab66j/Z4g2L3Wjigvh8X27PU8YAT5/13hXGFAgDwgkABAHhBoAAAvCBQAABeECgAAC8IFACAFwQKAMALAgUA4AWBAgDwgkABAHhBoAAAvCi4y2v9Wy3SikcntK6qeCgjzVeUar01pSFtviKsbX+ySVv/qPK0NH8gqnVhpdOd0nxbd1Kabxe7sErD2nyx07anXOx2a8lo76Wak1lp3sysU7xJcbG2Tf1M20dVNf2l+UhIewBqN9SAEq3LKxjU9o/abSWXZ4myGe01Tt0a57T9k3ba/gkXUHXGFQoAwAsCBQDgBYECAPCCQAEAeEGgAAC8IFAAAF4QKAAALwgUAIAXBAoAwAsCBQDgBYECAPCi4C6v3rGwtGLX2SrNh4u03qCE2N1UHtTWn7ECimsOEw5qPT29e5dL881O6xYz0/Z/aUmJNL/7nW5pPpppk+aDIW39pcGUNN+uValZm/b0mpnZO+Kd9C/Rjun9TfXSfDauHUNZsYtM7doqDmvz8eKCX67MzKykuFiaLyrS1m8BsVtM3D9ObPPKiE9Ysls7x0oix84ArlAAAF4QKAAALwgUAIAXBAoAwAsCBQDgBYECAPCCQAEAeEGgAAC8IFAAAF4QKAAALwgUAIAXBZfXBLVaGbMi7QZjhvWW5idWVUjzTXt3SvMNrU6aj4ldYf37lkrz4yp7SfPpPQek+T1alZcVZ7UeoF0tWhlWveuQ5vsktJ6q0pA235AUe57M7Hf7m6T5l7s6pfnut6LS/BvBLmk+I3ZVFYW0c74squ3T/lGtm2t4QjuoR/WNSPMDS7XtjwS1fsC2lNYFt7dZ67Pb16gdbzdfOP6YM1yhAAC8IFAAAF4QKAAALwgUAIAXBAoAwAsCBQDgBYECAPCCQAEAeEGgAAC8IFAAAF4QKAAALwouoxk/WOsNGt63XJrvH9O6s1LNWldVyGk9NwdapXErK0pK8wmxl6hU7EZrEnuDwsXa/u8f1bZnVzYszb/jtO6yp/e2S/PjO+ql+cZWrfvLzGzLO03SfFdQO8eGhrV9ur+tQZrvCGuPuSikHXPRTu2Y26ut3v63Tjvni7ZpfXMxsd6tPKjdIGBin6A0bRYLausvBFcoAAAvCBQAgBcECgDACwIFAOAFgQIA8IJAAQB4QaAAALwgUAAAXhAoAAAvCBQAgBcECgDAi4LLZSb1OaitOaX14hw4qJVnRYu1LEylte6pREQat7ISrWgom+2Q5usONEnzyZTWY1QS07b/Y8MT0vzQqNbtlg1oz1cgm5bmS7s7pfmIdUnzZmbD+vaX5kNB7TFHi7XnrCaldUl1hbSusGBQOyeLxLezgYD2HIdM2z9F4jEXymqvcZbSzvlYsdb3Z4GsNC5WoxWEKxQAgBcECgDACwIFAOAFgQIA8IJAAQB4QaAAALwgUAAAXhAoAAAvCBQAgBcECgDACwIFAOBFwDnnTvZGAAA+/LhCAQB4QaAAALwgUAAAXhAoAAAvCBQAgBcECgDACwIFAOAFgQIA8IJAAQB48f8AUgdiV6uawxcAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "✓ Preparação para ataque DLG completa!\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# from run import GLOBAL_GRADS, GLOBAL_INITIALS, GLOBAL_WEIGHTS, GLOBAL_METADATA\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"SELEÇÃO DE ALVO PARA ATAQUE DLG (FOCADO NA RODADA 1)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "if not GLOBAL_GRADS:\n",
        "    print(\"❌ Erro: Nenhum gradiente interceptado!\")\n",
        "else:\n",
        "    # Todas as chaves disponíveis\n",
        "    all_keys = list(GLOBAL_GRADS.keys())\n",
        "\n",
        "    # Filtrar rodada 1\n",
        "    vulnerable_targets = [k for k in all_keys if k[0] == 1]\n",
        "\n",
        "    if vulnerable_targets:\n",
        "        TARGET_ROUND, TARGET_CLIENT = vulnerable_targets[0]\n",
        "        print(\"✓ Alvo vulnerável encontrado na Rodada 1!\")\n",
        "    else:\n",
        "        print(\"⚠️ Nenhum alvo da rodada 1 — pegando aleatório\")\n",
        "        TARGET_ROUND, TARGET_CLIENT = random.choice(all_keys)\n",
        "\n",
        "    print(f\"\\n🎯 Alvo selecionado:\")\n",
        "    print(f\"   - Cliente: {TARGET_CLIENT}\")\n",
        "    print(f\"   - Rodada: {TARGET_ROUND}\")\n",
        "\n",
        "    # Gradientes interceptados\n",
        "    intercepted_gradients = GLOBAL_GRADS[(TARGET_ROUND, TARGET_CLIENT)]\n",
        "    intercepted_metadata = GLOBAL_METADATA.get((TARGET_ROUND, TARGET_CLIENT))\n",
        "\n",
        "    print(f\"\\n📊 Gradientes interceptados: {len(intercepted_gradients)} tensores\")\n",
        "\n",
        "    # converter para tensor\n",
        "    def to_tensor_float(g):\n",
        "        if isinstance(g, np.ndarray):\n",
        "            return torch.from_numpy(g).float()\n",
        "        return g.float()\n",
        "\n",
        "    attack_gradients = [to_tensor_float(g) for g in intercepted_gradients if g is not None]\n",
        "\n",
        "    print(\"   - Status: sem quantização (baseline)\")\n",
        "\n",
        "    # Pesos iniciais\n",
        "    intercepted_initial = GLOBAL_INITIALS[(TARGET_ROUND, TARGET_CLIENT)]\n",
        "\n",
        "    print(f\"\\n📦 Pesos iniciais interceptados: {len(intercepted_initial)} tensores\")\n",
        "\n",
        "    # Criar cliente alvo\n",
        "    target_client = ClienteComQuantizacao(\n",
        "        TARGET_CLIENT,\n",
        "        NIID,\n",
        "        NCLIENTS,\n",
        "        DIRICHLET_ALPHA,\n",
        "        quantizer=quantizer if ENABLE_QUANTIZATION else None,\n",
        "    )\n",
        "\n",
        "    img_tensor, label_idx = target_client.train_dataset[0]\n",
        "\n",
        "    real_image = img_tensor.unsqueeze(0)\n",
        "    real_label = torch.tensor([label_idx])\n",
        "\n",
        "    print(f\"\\n✓ Imagem real carregada:\")\n",
        "    print(f\"   - Shape: {real_image.shape}\")\n",
        "    print(f\"   - Label: {real_label.item()}\")\n",
        "\n",
        "    # Visualizar imagem\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    img_display = real_image[0].permute(1, 2, 0).numpy()\n",
        "    img_display = (img_display * 0.5) + 0.5\n",
        "    img_display = np.clip(img_display, 0, 1)\n",
        "    plt.imshow(img_display)\n",
        "    plt.title(f\"Imagem Real (Cliente {TARGET_CLIENT}, Round {TARGET_ROUND})\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "    print(\"=\"*60)\n",
        "    print(\"✓ Preparação para ataque DLG completa!\")\n",
        "    print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "🔍 VALIDAÇÃO DE GRADIENTES (usando pesos e gradientes interceptados)\n",
            "============================================================\n",
            "🎯 Alvo selecionado: cliente=0 | rodada=1\n",
            "\n",
            "📊 Total de gradientes interceptados: 10\n",
            "✓ Gradientes convertidos para tensores CUDA/CPU\n",
            "[Cliente 0] Device: cuda\n",
            "\n",
            "✓ Imagem real carregada: shape=torch.Size([1, 3, 32, 32]), label=0\n",
            "✓ Modelo reconstruído via utils.cria_modelo (compatível com os clientes).\n",
            "\n",
            "=== Comparando shapes de pesos ===\n",
            "body.0.weight                        model=(32, 3, 5, 5)  saved=(32, 3, 5, 5)\n",
            "body.0.bias                          model=(32,)  saved=(32,)\n",
            "body.2.weight                        model=(64, 32, 5, 5)  saved=(64, 32, 5, 5)\n",
            "body.2.bias                          model=(64,)  saved=(64,)\n",
            "body.4.weight                        model=(64, 64, 5, 5)  saved=(64, 64, 5, 5)\n",
            "body.4.bias                          model=(64,)  saved=(64,)\n",
            "body.6.weight                        model=(64, 64, 5, 5)  saved=(64, 64, 5, 5)\n",
            "body.6.bias                          model=(64,)  saved=(64,)\n",
            "fc.0.weight                          model=(4, 4096)  saved=(4, 4096)\n",
            "fc.0.bias                            model=(4,)  saved=(4,)\n",
            "✓ Todos os shapes são compatíveis!\n",
            "✓ Pesos carregados com sucesso.\n",
            "\n",
            "🧮 Recalculando gradientes locais...\n",
            "\n",
            "⚖️ Comparando gradientes...\n",
            "📉 Erro relativo médio = 0.002474\n",
            "⚠️ Pequenas diferenças — ainda é possível reconstruir imagem.\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# ===============================================================\n",
        "# 🔍 VALIDAÇÃO DE GRADIENTES — VERSÃO FINAL COMPATÍVEL\n",
        "# ===============================================================\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import logging\n",
        "import torch\n",
        "import numpy as np\n",
        "import utils\n",
        "\n",
        "logging.basicConfig(level=logging.ERROR)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "print(f\"{'='*60}\")\n",
        "print(\"🔍 VALIDAÇÃO DE GRADIENTES (usando pesos e gradientes interceptados)\")\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "# ===============================================================\n",
        "# 1) Obter gradientes/pesos dos globais criados na simulação\n",
        "# ===============================================================\n",
        "GLOBAL_GRADS = globals().get(\"GLOBAL_GRADS\", {})\n",
        "GLOBAL_INITIALS = globals().get(\"GLOBAL_INITIALS\", {})\n",
        "GLOBAL_METADATA = globals().get(\"GLOBAL_METADATA\", {})\n",
        "\n",
        "if not GLOBAL_GRADS:\n",
        "    raise ValueError(\"Nenhum gradiente interceptado encontrado em GLOBAL_GRADS. Rode a simulação primeiro!\")\n",
        "\n",
        "# Escolher rodadas vulneráveis (1)\n",
        "keys = list(GLOBAL_GRADS.keys())\n",
        "keys_r1 = [k for k in keys if k[0] == 1]\n",
        "\n",
        "if not keys_r1:\n",
        "    print(\"⚠️ AVISO: Não encontrei dados da Rodada 1 (SGD, batch=1). Selecionando chave aleatória.\")\n",
        "    keys_r1 = keys\n",
        "\n",
        "TARGET_ROUND, TARGET_CLIENT = keys_r1[0]\n",
        "print(f\"🎯 Alvo selecionado: cliente={TARGET_CLIENT} | rodada={TARGET_ROUND}\")\n",
        "\n",
        "# Carregar gradientes e pesos iniciais\n",
        "intercepted_gradients = GLOBAL_GRADS[(TARGET_ROUND, TARGET_CLIENT)]\n",
        "intercepted_initial = GLOBAL_INITIALS[(TARGET_ROUND, TARGET_CLIENT)]\n",
        "\n",
        "if intercepted_gradients is None or intercepted_initial is None:\n",
        "    raise ValueError(\"Dados interceptados incompletos para esse cliente.\")\n",
        "\n",
        "print(f\"\\n📊 Total de gradientes interceptados: {len(intercepted_gradients)}\")\n",
        "\n",
        "\n",
        "# ===============================================================\n",
        "# 2) Converter gradientes numpy -> torch\n",
        "# ===============================================================\n",
        "\n",
        "def to_tensor(g):\n",
        "    if g is None:\n",
        "        return None\n",
        "    if isinstance(g, torch.Tensor):\n",
        "        return g.float().to(device)\n",
        "    if isinstance(g, np.ndarray):\n",
        "        return torch.from_numpy(g).float().to(device)\n",
        "    return torch.tensor(g, dtype=torch.float32).to(device)\n",
        "\n",
        "attack_gradients = [to_tensor(g) for g in intercepted_gradients]\n",
        "print(f\"✓ Gradientes convertidos para tensores CUDA/CPU\")\n",
        "\n",
        "\n",
        "# ===============================================================\n",
        "# 3) Criar o cliente temporário e pegar a imagem real índice 0\n",
        "# ===============================================================\n",
        "PATH = \"/home/nicolas/Documentos/topicos_sistemas_distribuidos/trabalho/DATASETS/Pokedex_v14\"\n",
        "\n",
        "temp_client = ClienteComQuantizacao(\n",
        "    TARGET_CLIENT,\n",
        "    NIID,\n",
        "    NCLIENTS,\n",
        "    DIRICHLET_ALPHA,\n",
        "    dataset_path=PATH,\n",
        "    quantizer=None\n",
        ")\n",
        "\n",
        "img_tensor_norm, label_idx = temp_client.train_dataset[0]\n",
        "real_image_normalized = img_tensor_norm.unsqueeze(0).to(device)\n",
        "real_label = torch.tensor([label_idx]).to(device)\n",
        "\n",
        "print(f\"\\n✓ Imagem real carregada: shape={real_image_normalized.shape}, label={real_label.item()}\")\n",
        "\n",
        "\n",
        "# ===============================================================\n",
        "# 4) Reconstruir modelo usando exatamente o mesmo factory\n",
        "# ===============================================================\n",
        "dataset_for_model = temp_client.full_dataset\n",
        "modelo = utils.cria_modelo(\"pokemon\", dataset=dataset_for_model).to(device)\n",
        "modelo.eval()\n",
        "\n",
        "print(\"✓ Modelo reconstruído via utils.cria_modelo (compatível com os clientes).\")\n",
        "\n",
        "\n",
        "# ===============================================================\n",
        "# 5) Converter pesos iniciais interceptados -> tensores\n",
        "# ===============================================================\n",
        "weights_load = []\n",
        "for w in intercepted_initial:\n",
        "    if isinstance(w, np.ndarray):\n",
        "        weights_load.append(torch.from_numpy(w).float().to(device))\n",
        "    elif isinstance(w, torch.Tensor):\n",
        "        weights_load.append(w.float().to(device))\n",
        "    else:\n",
        "        weights_load.append(torch.tensor(w, dtype=torch.float32).to(device))\n",
        "\n",
        "# Mostrar shapes esperados e recebidos\n",
        "print(\"\\n=== Comparando shapes de pesos ===\")\n",
        "state_keys = list(modelo.state_dict().keys())\n",
        "state_shapes = [tuple(v.shape) for v in modelo.state_dict().values()]\n",
        "saved_shapes = [tuple(w.shape) for w in weights_load]\n",
        "\n",
        "for k, a, b in zip(state_keys, state_shapes, saved_shapes):\n",
        "    print(f\"{k:35s}  model={a}  saved={b}\")\n",
        "    if a != b:\n",
        "        raise ValueError(f\"ERRO: Shape incompatível em {k}: esperado {a}, recebido {b}\")\n",
        "\n",
        "print(\"✓ Todos os shapes são compatíveis!\")\n",
        "\n",
        "\n",
        "# ===============================================================\n",
        "# 6) Carregar pesos no modelo\n",
        "# ===============================================================\n",
        "sd = modelo.state_dict()\n",
        "new_sd = {}\n",
        "\n",
        "for (k, v), w in zip(sd.items(), weights_load):\n",
        "    new_sd[k] = w\n",
        "\n",
        "modelo.load_state_dict(new_sd)\n",
        "print(\"✓ Pesos carregados com sucesso.\")\n",
        "\n",
        "\n",
        "# ===============================================================\n",
        "# 7) Calcular gradientes locais usando one-hot + cross entropy\n",
        "# ===============================================================\n",
        "print(\"\\n🧮 Recalculando gradientes locais...\")\n",
        "\n",
        "label_onehot = utils.label_to_onehot(real_label, num_classes=len(temp_client.full_dataset.classes))\n",
        "\n",
        "output = modelo(real_image_normalized)\n",
        "loss = utils.cross_entropy_for_onehot(output, label_onehot)\n",
        "\n",
        "grads_calculated = torch.autograd.grad(loss, modelo.parameters())\n",
        "\n",
        "\n",
        "# ===============================================================\n",
        "# 8) Comparar gradientes\n",
        "# ===============================================================\n",
        "print(\"\\n⚖️ Comparando gradientes...\")\n",
        "\n",
        "diffs = []\n",
        "for g_int, g_calc in zip(attack_gradients, grads_calculated):\n",
        "    d = torch.norm(g_int - g_calc).item()\n",
        "    n = torch.norm(g_calc).item()\n",
        "    diffs.append(d / (n + 1e-8))\n",
        "\n",
        "avg = float(np.mean(diffs))\n",
        "print(f\"📉 Erro relativo médio = {avg:.6f}\")\n",
        "\n",
        "if avg < 0.001:\n",
        "    print(\"✅ Gradientes idênticos — ataque DLG pode rodar com precisão máxima.\")\n",
        "elif avg < 0.1:\n",
        "    print(\"⚠️ Pequenas diferenças — ainda é possível reconstruir imagem.\")\n",
        "else:\n",
        "    print(\"❌ Erros grandes — pesos ou imagem não correspondem.\")\n",
        "\n",
        "\n",
        "print(f\"{'='*60}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Implementar Ataque DLG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "EXECUÇÃO DO ATAQUE iDLG (Corrigido para nova arquitetura)\n",
            "============================================================\n",
            "\n",
            "🧠 Inferindo label pelo iDLG...\n",
            "✓ Label inferido via iDLG: 0\n",
            "✓ Label real:               0\n",
            "\n",
            "🚀 Iniciando Ataque com 3 restarts...\n",
            "\n",
            "🔄 Tentativa 1: Gaussian\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 300/300 [01:40<00:00,  2.98it/s, loss=2.24]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   🏆 Melhor resultado atualizado: 2.240429\n",
            "\n",
            "🔄 Tentativa 2: Zeros\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 300/300 [00:02<00:00, 113.53it/s, loss=1.9]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   🏆 Melhor resultado atualizado: 1.901196\n",
            "\n",
            "🔄 Tentativa 3: Uniform[-0.5,0.5]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 300/300 [01:42<00:00,  2.92it/s, loss=1.91]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✓ Ataque finalizado — melhor loss: 1.901196\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📈 Métricas:\n",
            "   - MSE:  0.075789\n",
            "   - PSNR: 11.20 dB\n",
            "   - SSIM indisponível\n"
          ]
        }
      ],
      "source": [
        "# ===============================================================\n",
        "# Ataque iDLG — Versão corrigida para nova arquitetura e globais\n",
        "# ===============================================================\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import utils\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "print(f\"{'='*60}\")\n",
        "print(\"EXECUÇÃO DO ATAQUE iDLG (Corrigido para nova arquitetura)\")\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "# ===============================================================\n",
        "# 1. VALIDAR ENTRADAS NECESSÁRIAS\n",
        "# ===============================================================\n",
        "vars_needed = [\"modelo\", \"attack_gradients\", \"real_image_normalized\", \"real_label\"]\n",
        "for v in vars_needed:\n",
        "    if v not in globals():\n",
        "        raise ValueError(f\"Variável necessária '{v}' não encontrada. Rode o bloco de validação primeiro!\")\n",
        "\n",
        "real_image = real_image_normalized  # renomeio para conveniência\n",
        "\n",
        "# ===============================================================\n",
        "# 2. INFERIR LABEL PELO GRADIENTE DA FC.bias\n",
        "# ===============================================================\n",
        "print(\"\\n🧠 Inferindo label pelo iDLG...\")\n",
        "\n",
        "# O gradiente da última camada (bias) normalmente é o último tensor\n",
        "fc_bias_grad = attack_gradients[-1].view(-1)\n",
        "\n",
        "inferred_label = torch.argmin(fc_bias_grad).item()\n",
        "print(f\"✓ Label inferido via iDLG: {inferred_label}\")\n",
        "print(f\"✓ Label real:               {real_label.item()}\")\n",
        "\n",
        "num_classes = len(fc_bias_grad)\n",
        "label_onehot = utils.label_to_onehot(\n",
        "    torch.tensor([inferred_label], device=device),\n",
        "    num_classes=num_classes\n",
        ")\n",
        "\n",
        "# ===============================================================\n",
        "# 3. FUNÇÃO DO ATAQUE (corrigida)\n",
        "# ===============================================================\n",
        "def run_ataque_with_restarts(modelo, target_onehot, target_grads,\n",
        "                             num_iterations=300, n_restarts=3):\n",
        "\n",
        "    best_loss = float('inf')\n",
        "    best_image = None\n",
        "\n",
        "    print(f\"\\n🚀 Iniciando Ataque com {n_restarts} restarts...\")\n",
        "\n",
        "    for attempt in range(n_restarts):\n",
        "\n",
        "        if attempt == 0:\n",
        "            dummy = torch.randn_like(real_image, device=device).requires_grad_(True)\n",
        "            init_type = \"Gaussian\"\n",
        "        elif attempt == 1:\n",
        "            dummy = torch.zeros_like(real_image, device=device).requires_grad_(True)\n",
        "            init_type = \"Zeros\"\n",
        "        else:\n",
        "            dummy = (torch.rand_like(real_image, device=device) - 0.5).requires_grad_(True)\n",
        "            init_type = \"Uniform[-0.5,0.5]\"\n",
        "\n",
        "        print(f\"\\n🔄 Tentativa {attempt+1}: {init_type}\")\n",
        "\n",
        "        optimizer = torch.optim.LBFGS([dummy], lr=0.05)\n",
        "\n",
        "        pbar = tqdm(range(num_iterations))\n",
        "        for _ in pbar:\n",
        "\n",
        "            def closure():\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                out = modelo(dummy)\n",
        "                loss_ce = utils.cross_entropy_for_onehot(out, target_onehot)\n",
        "\n",
        "                dummy_grads = torch.autograd.grad(\n",
        "                    loss_ce,\n",
        "                    modelo.parameters(),\n",
        "                    create_graph=False,\n",
        "                    retain_graph=False\n",
        "                )\n",
        "\n",
        "                grad_diff = 0\n",
        "                for g1, g2 in zip(dummy_grads, target_grads):\n",
        "                    g2 = g2.to(device)\n",
        "                    if g1.shape == g2.shape:\n",
        "                        grad_diff += ((g1 - g2)**2).mean()\n",
        "\n",
        "                # --- TV Loss com força maior ---\n",
        "                tv = 1e-2 * (\n",
        "                    torch.sum(torch.abs(dummy[:, :, :, :-1] - dummy[:, :, :, 1:])) +\n",
        "                    torch.sum(torch.abs(dummy[:, :, :-1, :] - dummy[:, :, 1:, :]))\n",
        "                )\n",
        "\n",
        "                total = grad_diff + tv\n",
        "                total.backward()\n",
        "                return total\n",
        "\n",
        "            loss_val = optimizer.step(closure)\n",
        "\n",
        "            # --- Clipping anti-NaN ---\n",
        "            with torch.no_grad():\n",
        "                dummy.data.clamp_(-1, 1)\n",
        "\n",
        "            if torch.isnan(dummy).any():\n",
        "                print(\"⚠ NaN detectado → Reinicializando tentativa.\")\n",
        "                break\n",
        "\n",
        "            pbar.set_postfix(loss=float(loss_val))\n",
        "\n",
        "        # salvar melhor tentativa\n",
        "        if float(loss_val) < best_loss:\n",
        "            best_loss = float(loss_val)\n",
        "            best_image = dummy.detach().cpu().clone()\n",
        "            print(f\"   🏆 Melhor resultado atualizado: {best_loss:.6f}\")\n",
        "\n",
        "    return best_image, best_loss\n",
        "\n",
        "\n",
        "# ===============================================================\n",
        "# 4. EXECUTAR ATAQUE\n",
        "# ===============================================================\n",
        "final_best_image, final_loss = run_ataque_with_restarts(\n",
        "    modelo,\n",
        "    label_onehot,\n",
        "    attack_gradients,\n",
        "    num_iterations=300,\n",
        "    n_restarts=3\n",
        ")\n",
        "\n",
        "print(f\"\\n✓ Ataque finalizado — melhor loss: {final_loss:.6f}\")\n",
        "\n",
        "# ===============================================================\n",
        "# 5. VISUALIZAÇÃO\n",
        "# ===============================================================\n",
        "def tensor_to_img_display(t):\n",
        "    img = t.detach().cpu().squeeze().permute(1,2,0).numpy()\n",
        "    img = (img * 0.5) + 0.5   # depende do dataset!\n",
        "    img = np.clip(img, 0, 1)\n",
        "    return img\n",
        "\n",
        "img_real = tensor_to_img_display(real_image)\n",
        "img_fake = tensor_to_img_display(final_best_image)\n",
        "\n",
        "fig, axes = plt.subplots(1,2, figsize=(10,5))\n",
        "axes[0].imshow(img_real); axes[0].set_title(\"Imagem Real\"); axes[0].axis(\"off\")\n",
        "axes[1].imshow(img_fake); axes[1].set_title(\"Reconstruída (iDLG)\"); axes[1].axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "# ===============================================================\n",
        "# 6. MÉTRICAS\n",
        "# ===============================================================\n",
        "print(\"\\n📈 Métricas:\")\n",
        "\n",
        "mse = np.mean((img_real - img_fake)**2)\n",
        "print(f\"   - MSE:  {mse:.6f}\")\n",
        "\n",
        "if mse > 1e-10:\n",
        "    psnr = 10*np.log10(1.0/mse)\n",
        "    print(f\"   - PSNR: {psnr:.2f} dB\")\n",
        "else:\n",
        "    print(\"   - PSNR: infinito\")\n",
        "\n",
        "try:\n",
        "    from skimage.metrics import structural_similarity as ssim\n",
        "    ssim_val = ssim(img_real, img_fake, channel_axis=2)\n",
        "    print(f\"   - SSIM: {ssim_val:.4f}\")\n",
        "except:\n",
        "    print(\"   - SSIM indisponível\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (MO809_2)",
      "language": "python",
      "name": "mo809_2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
